{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh941213/NLP/blob/main/%EC%B6%94%EC%B6%9C%EC%9A%94%EC%95%BDcode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install libraries"
      ],
      "metadata": {
        "id": "L2OYr54LqWUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MeCab\n",
        "- konlpy 설치 후 MeCab 설치\n",
        "  - https://konlpy-ko.readthedocs.io/ko/v0.4.3/install/ 참고"
      ],
      "metadata": {
        "id": "s8p0-4iMCdG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MqrufjJCjRi",
        "outputId": "e8761538-5eb7-405e-ccd3-afc588ae09b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4hWbrCrC3hX",
        "outputId": "d43e2036-c6fd-4754-e3d7-61df5838f1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,121 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,162 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,390 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,099 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,959 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,540 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,076 kB]\n",
            "Fetched 13.6 MB in 5s (2,727 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install curl git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTSAbqleC9IW",
        "outputId": "209892cf-5fe9-4343-946e-d7546154e675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.12).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libcurl4 libcurl4-openssl-dev\n",
            "Suggested packages:\n",
            "  libcurl4-doc libidn11-dev libkrb5-dev libldap2-dev librtmp-dev\n",
            "The following packages will be upgraded:\n",
            "  curl libcurl4 libcurl4-openssl-dev\n",
            "3 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 681 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl4-openssl-dev amd64 7.58.0-2ubuntu3.20 [302 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 curl amd64 7.58.0-2ubuntu3.20 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl4 amd64 7.58.0-2ubuntu3.20 [220 kB]\n",
            "Fetched 681 kB in 2s (382 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../libcurl4-openssl-dev_7.58.0-2ubuntu3.20_amd64.deb ...\n",
            "Unpacking libcurl4-openssl-dev:amd64 (7.58.0-2ubuntu3.20) over (7.58.0-2ubuntu3.19) ...\n",
            "Preparing to unpack .../curl_7.58.0-2ubuntu3.20_amd64.deb ...\n",
            "Unpacking curl (7.58.0-2ubuntu3.20) over (7.58.0-2ubuntu3.19) ...\n",
            "Preparing to unpack .../libcurl4_7.58.0-2ubuntu3.20_amd64.deb ...\n",
            "Unpacking libcurl4:amd64 (7.58.0-2ubuntu3.20) over (7.58.0-2ubuntu3.19) ...\n",
            "Setting up libcurl4:amd64 (7.58.0-2ubuntu3.20) ...\n",
            "Setting up libcurl4-openssl-dev:amd64 (7.58.0-2ubuntu3.20) ...\n",
            "Setting up curl (7.58.0-2ubuntu3.20) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVL-sEJ4DP72",
        "outputId": "a3b313bb-59e6-4697-e8fd-9abe642823d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing automake (A dependency for mecab-ko)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  autoconf autotools-dev libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev libsigsegv2 m4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 1,082 kB of archives.\n",
            "After this operation, 3,994 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Fetched 1,082 kB in 2s (608 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Install mecab-ko\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 1381k  100 1381k    0     0   366k      0  0:00:03  0:00:03 --:--:--  945k\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  2545k      0  0:00:19  0:00:19 --:--:-- 7955k\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./EP.csv ... 51\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./MM.csv ... 453\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./NP.csv ... 342\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./NR.csv ... 482\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./VX.csv ... 125\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./J.csv ... 416\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./VA.csv ... 2360\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /tmp/mecab-python-0.996\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141799 sha256=f84c105349aaad0082b722af4cf7db6f2715f2694a9467347373c6733686a4c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "    Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiprocess"
      ],
      "metadata": {
        "id": "Mf3BZBuWquhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install multiprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-PppzRmVzJV",
        "outputId": "8591c866-a77c-4e1d-9bc6-997a333d539b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.5.1 in /usr/local/lib/python3.7/dist-packages (from multiprocess) (0.3.5.1)\n",
            "Installing collected packages: multiprocess\n",
            "Successfully installed multiprocess-0.70.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "kEypTU79q-DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70b9lkCuWcbV",
        "outputId": "049c1cf3-8ee6-4afe-b2e0-3cd22742de5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 29.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 20.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyRouge"
      ],
      "metadata": {
        "id": "5tvpMkjArCP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path '/content/pyrouge/tools/ROUGE-1.5.5'"
      ],
      "metadata": {
        "id": "OLnPVfH6rE9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b9f5ed-a4ed-483d-8e67-b4b7feedfe8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyrouge\n",
            "  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 3.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191621 sha256=027ec35cea1fa330666c83f0bcc5adf209fd1bfae9ad5e3acb69ee8c32d60688\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/35/6a/ffb9a1f51b2b00fee42e7f67f5a5d8e10c67d048cda09ccd57\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "  Downloading https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "\u001b[K     | 202 kB 843 kB/s\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Name: pyrouge\n",
            "Version: 0.1.3\n",
            "Summary: A Python wrapper for the ROUGE summarization evaluation package.\n",
            "Home-page: https://github.com/noutenki/pyrouge\n",
            "Author: Benjamin Heinzerling, Anders Johannsen\n",
            "Author-email: benjamin.heinzerling@h-its.org\n",
            "License: LICENSE.txt\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "Cloning into 'pyrouge'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Total 393 (delta 0), reused 0 (delta 0), pack-reused 393\u001b[K\n",
            "Receiving objects: 100% (393/393), 298.74 KiB | 1.21 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "2022-09-07 06:46:39,668 [MainThread  ] [INFO ]  Set ROUGE home directory to /content/pyrouge/tools/ROUGE-1.5.5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libxml-parser-perl"
      ],
      "metadata": {
        "id": "kSKxoZ7wABXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ecb665-3195-48a3-bb8a-61f7508f8b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libauthen-sasl-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtimedate-perl libtry-tiny-perl liburi-perl libwww-perl\n",
            "  libwww-robotrules-perl netbase perl-openssl-defaults\n",
            "Suggested packages:\n",
            "  libdigest-hmac-perl libgssapi-perl libcrypt-ssleay-perl libauthen-ntlm-perl\n",
            "The following NEW packages will be installed:\n",
            "  libauthen-sasl-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtimedate-perl libtry-tiny-perl liburi-perl libwww-perl\n",
            "  libwww-robotrules-perl libxml-parser-perl netbase perl-openssl-defaults\n",
            "0 upgraded, 31 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 1,711 kB of archives.\n",
            "After this operation, 5,553 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 netbase all 5.4 [12.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdata-dump-perl all 1.23-1 [27.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-listing-perl all 6.04-1 [9,774 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfont-afm-perl all 1.20-2 [13.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-form-perl all 6.03-1 [23.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tree-perl all 5.07-1 [200 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-format-perl all 2.12-1 [41.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-cookies-perl all 6.04-1 [17.2 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libhttp-daemon-perl all 6.01-1ubuntu0.1 [15.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-negotiate-perl all 6.00-2 [13.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 perl-openssl-defaults amd64 3build1 [7,012 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnet-ssleay-perl amd64 1.84-1ubuntu0.2 [283 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libio-socket-ssl-perl all 2.060-3~ubuntu18.04.1 [173 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnet-http-perl all 6.17-1 [22.7 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtry-tiny-perl all 0.30-1 [20.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwww-robotrules-perl all 6.01-1 [14.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwww-perl all 6.31-1ubuntu0.1 [137 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-protocol-https-perl all 6.07-2 [8,284 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnet-smtp-ssl-perl all 1.04-1 [5,948 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmailtools-perl all 2.18-1 [74.0 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-parser-perl amd64 2.44-2build3 [199 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libauthen-sasl-perl all 2.1600-1 [48.7 kB]\n",
            "Fetched 1,711 kB in 2s (912 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 31.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package netbase.\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../00-netbase_5.4_all.deb ...\n",
            "Unpacking netbase (5.4) ...\n",
            "Selecting previously unselected package libdata-dump-perl.\n",
            "Preparing to unpack .../01-libdata-dump-perl_1.23-1_all.deb ...\n",
            "Unpacking libdata-dump-perl (1.23-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../02-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../03-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../04-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libfile-listing-perl.\n",
            "Preparing to unpack .../05-libfile-listing-perl_6.04-1_all.deb ...\n",
            "Unpacking libfile-listing-perl (6.04-1) ...\n",
            "Selecting previously unselected package libfont-afm-perl.\n",
            "Preparing to unpack .../06-libfont-afm-perl_1.20-2_all.deb ...\n",
            "Unpacking libfont-afm-perl (1.20-2) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../07-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../08-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../09-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../10-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../11-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../12-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libhtml-form-perl.\n",
            "Preparing to unpack .../13-libhtml-form-perl_6.03-1_all.deb ...\n",
            "Unpacking libhtml-form-perl (6.03-1) ...\n",
            "Selecting previously unselected package libhtml-tree-perl.\n",
            "Preparing to unpack .../14-libhtml-tree-perl_5.07-1_all.deb ...\n",
            "Unpacking libhtml-tree-perl (5.07-1) ...\n",
            "Selecting previously unselected package libhtml-format-perl.\n",
            "Preparing to unpack .../15-libhtml-format-perl_2.12-1_all.deb ...\n",
            "Unpacking libhtml-format-perl (2.12-1) ...\n",
            "Selecting previously unselected package libhttp-cookies-perl.\n",
            "Preparing to unpack .../16-libhttp-cookies-perl_6.04-1_all.deb ...\n",
            "Unpacking libhttp-cookies-perl (6.04-1) ...\n",
            "Selecting previously unselected package libhttp-daemon-perl.\n",
            "Preparing to unpack .../17-libhttp-daemon-perl_6.01-1ubuntu0.1_all.deb ...\n",
            "Unpacking libhttp-daemon-perl (6.01-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libhttp-negotiate-perl.\n",
            "Preparing to unpack .../18-libhttp-negotiate-perl_6.00-2_all.deb ...\n",
            "Unpacking libhttp-negotiate-perl (6.00-2) ...\n",
            "Selecting previously unselected package perl-openssl-defaults:amd64.\n",
            "Preparing to unpack .../19-perl-openssl-defaults_3build1_amd64.deb ...\n",
            "Unpacking perl-openssl-defaults:amd64 (3build1) ...\n",
            "Selecting previously unselected package libnet-ssleay-perl.\n",
            "Preparing to unpack .../20-libnet-ssleay-perl_1.84-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libnet-ssleay-perl (1.84-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libio-socket-ssl-perl.\n",
            "Preparing to unpack .../21-libio-socket-ssl-perl_2.060-3~ubuntu18.04.1_all.deb ...\n",
            "Unpacking libio-socket-ssl-perl (2.060-3~ubuntu18.04.1) ...\n",
            "Selecting previously unselected package libnet-http-perl.\n",
            "Preparing to unpack .../22-libnet-http-perl_6.17-1_all.deb ...\n",
            "Unpacking libnet-http-perl (6.17-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../23-libtry-tiny-perl_0.30-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.30-1) ...\n",
            "Selecting previously unselected package libwww-robotrules-perl.\n",
            "Preparing to unpack .../24-libwww-robotrules-perl_6.01-1_all.deb ...\n",
            "Unpacking libwww-robotrules-perl (6.01-1) ...\n",
            "Selecting previously unselected package libwww-perl.\n",
            "Preparing to unpack .../25-libwww-perl_6.31-1ubuntu0.1_all.deb ...\n",
            "Unpacking libwww-perl (6.31-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblwp-protocol-https-perl.\n",
            "Preparing to unpack .../26-liblwp-protocol-https-perl_6.07-2_all.deb ...\n",
            "Unpacking liblwp-protocol-https-perl (6.07-2) ...\n",
            "Selecting previously unselected package libnet-smtp-ssl-perl.\n",
            "Preparing to unpack .../27-libnet-smtp-ssl-perl_1.04-1_all.deb ...\n",
            "Unpacking libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Selecting previously unselected package libmailtools-perl.\n",
            "Preparing to unpack .../28-libmailtools-perl_2.18-1_all.deb ...\n",
            "Unpacking libmailtools-perl (2.18-1) ...\n",
            "Selecting previously unselected package libxml-parser-perl.\n",
            "Preparing to unpack .../29-libxml-parser-perl_2.44-2build3_amd64.deb ...\n",
            "Unpacking libxml-parser-perl (2.44-2build3) ...\n",
            "Selecting previously unselected package libauthen-sasl-perl.\n",
            "Preparing to unpack .../30-libauthen-sasl-perl_2.1600-1_all.deb ...\n",
            "Unpacking libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libtry-tiny-perl (0.30-1) ...\n",
            "Setting up libfont-afm-perl (1.20-2) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up perl-openssl-defaults:amd64 (3build1) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libdata-dump-perl (1.23-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libnet-http-perl (6.17-1) ...\n",
            "Setting up libwww-robotrules-perl (6.01-1) ...\n",
            "Setting up libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up netbase (5.4) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libnet-ssleay-perl (1.84-1ubuntu0.2) ...\n",
            "Setting up libio-socket-ssl-perl (2.060-3~ubuntu18.04.1) ...\n",
            "Setting up libhtml-tree-perl (5.07-1) ...\n",
            "Setting up libfile-listing-perl (6.04-1) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libhttp-negotiate-perl (6.00-2) ...\n",
            "Setting up libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Setting up libhtml-format-perl (2.12-1) ...\n",
            "Setting up libhttp-cookies-perl (6.04-1) ...\n",
            "Setting up libhttp-daemon-perl (6.01-1ubuntu0.1) ...\n",
            "Setting up libhtml-form-perl (6.03-1) ...\n",
            "Setting up libmailtools-perl (2.18-1) ...\n",
            "Setting up liblwp-protocol-https-perl (6.07-2) ...\n",
            "Setting up libwww-perl (6.31-1ubuntu0.1) ...\n",
            "Setting up libxml-parser-perl (2.44-2build3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd pyrouge/tools/ROUGE-1.5.5/data\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "cd WordNet-2.0-Exceptions\n",
        "rm WordNet-2.0.exc.db # only if exist\n",
        "\n",
        "./buildExeptionDB.pl . exc WordNet-2.0.exc.db\n",
        "cd ../\n",
        "ln -s WordNet-2.0-Exceptions/WordNet-2.0.exc.db WordNet-2.0.exc.db"
      ],
      "metadata": {
        "id": "jYth5j1Xrg5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e534e6d8-8dd9-4269-bc50-52bff1dc3991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "impanelling\n",
            "impelled\n",
            "impelling\n",
            "implied\n",
            "inbred\n",
            "incurred\n",
            "incurring\n",
            "indemnified\n",
            "indwelt\n",
            "inferred\n",
            "inferring\n",
            "initialled\n",
            "initialling\n",
            "inlaid\n",
            "insetting\n",
            "inspanned\n",
            "inspanning\n",
            "installed\n",
            "installing\n",
            "intensified\n",
            "interbred\n",
            "intercropped\n",
            "intercropping\n",
            "intercutting\n",
            "interlaid\n",
            "interlapped\n",
            "interlapping\n",
            "intermarried\n",
            "intermitted\n",
            "intermitting\n",
            "interpled\n",
            "interred\n",
            "interring\n",
            "interstratified\n",
            "interwove\n",
            "interwoven\n",
            "intromitted\n",
            "intromitting\n",
            "inwove\n",
            "inwoven\n",
            "inwrapped\n",
            "inwrapping\n",
            "is\n",
            "jabbed\n",
            "jabbing\n",
            "jagged\n",
            "jagging\n",
            "jammed\n",
            "jamming\n",
            "japanned\n",
            "japanning\n",
            "jarred\n",
            "jarring\n",
            "jellied\n",
            "jellified\n",
            "jemmied\n",
            "jerry-built\n",
            "jetted\n",
            "jetting\n",
            "jewelled\n",
            "jewelling\n",
            "jibbed\n",
            "jibbing\n",
            "jigged\n",
            "jigging\n",
            "jimmied\n",
            "jitterbugged\n",
            "jitterbugging\n",
            "jobbed\n",
            "jobbing\n",
            "jog-trotted\n",
            "jog-trotting\n",
            "jogged\n",
            "jogging\n",
            "joined_battle\n",
            "joined_forces\n",
            "joining_battle\n",
            "joining_forces\n",
            "joins_battle\n",
            "joins_forces\n",
            "jollied\n",
            "jollified\n",
            "jotted\n",
            "jotting\n",
            "joy-ridden\n",
            "joy-rode\n",
            "joypopped\n",
            "joypopping\n",
            "jugged\n",
            "jugging\n",
            "jumped_off\n",
            "jumping_off\n",
            "jumps_off\n",
            "justified\n",
            "jutted\n",
            "jutting\n",
            "kenned\n",
            "kennelled\n",
            "kennelling\n",
            "kenning\n",
            "kent\n",
            "kept\n",
            "kernelled\n",
            "kernelling\n",
            "kidded\n",
            "kidding\n",
            "kidnapped\n",
            "kidnapping\n",
            "kipped\n",
            "kipping\n",
            "knapped\n",
            "knapping\n",
            "kneecapped\n",
            "kneecapping\n",
            "knelt\n",
            "knew\n",
            "knitted\n",
            "knitting\n",
            "knobbed\n",
            "knobbing\n",
            "knotted\n",
            "knotting\n",
            "known\n",
            "ko'd\n",
            "ko'ing\n",
            "ko's\n",
            "labelled\n",
            "labelling\n",
            "laden\n",
            "ladyfied\n",
            "ladyfies\n",
            "ladyfying\n",
            "lagged\n",
            "lagging\n",
            "laid\n",
            "lain\n",
            "lallygagged\n",
            "lallygagging\n",
            "lammed\n",
            "lamming\n",
            "lapidified\n",
            "lapped\n",
            "lapping\n",
            "laurelled\n",
            "laurelling\n",
            "lay\n",
            "layed_for\n",
            "laying_for\n",
            "lays_for\n",
            "leant\n",
            "leapfrogged\n",
            "leapfrogging\n",
            "leapt\n",
            "learnt\n",
            "leaves_undone\n",
            "leaving_undone\n",
            "led\n",
            "left\n",
            "left_undone\n",
            "lent\n",
            "letting\n",
            "levelled\n",
            "levelling\n",
            "levied\n",
            "libelled\n",
            "libelling\n",
            "lignified\n",
            "lipped\n",
            "lipping\n",
            "liquefied\n",
            "liquified\n",
            "lit\n",
            "lobbed\n",
            "lobbied\n",
            "lobbing\n",
            "logged\n",
            "logging\n",
            "looked_towards\n",
            "looking_towards\n",
            "looks_towards\n",
            "lopped\n",
            "lopping\n",
            "lost\n",
            "lotted\n",
            "lotting\n",
            "lugged\n",
            "lugging\n",
            "lullabied\n",
            "lying\n",
            "machine-gunned\n",
            "machine-gunning\n",
            "madded\n",
            "madding\n",
            "made\n",
            "magnified\n",
            "manned\n",
            "manning\n",
            "manumitted\n",
            "manumitting\n",
            "mapped\n",
            "mapping\n",
            "marcelled\n",
            "marcelling\n",
            "marred\n",
            "married\n",
            "marring\n",
            "marshalled\n",
            "marshalling\n",
            "marvelled\n",
            "marvelling\n",
            "matted\n",
            "matting\n",
            "meant\n",
            "medalled\n",
            "medalling\n",
            "met\n",
            "metalled\n",
            "metalling\n",
            "metrified\n",
            "might\n",
            "militated_against\n",
            "militates_against\n",
            "militating_against\n",
            "mimicked\n",
            "mimicking\n",
            "minified\n",
            "misapplied\n",
            "misbecame\n",
            "miscarried\n",
            "misdealt\n",
            "misfitted\n",
            "misfitting\n",
            "misgave\n",
            "misgiven\n",
            "mishitting\n",
            "mislaid\n",
            "misled\n",
            "mispled\n",
            "misspelt\n",
            "misspent\n",
            "mistaken\n",
            "mistook\n",
            "misunderstood\n",
            "mobbed\n",
            "mobbing\n",
            "modelled\n",
            "modelling\n",
            "modified\n",
            "mollified\n",
            "molten\n",
            "mopped\n",
            "mopping\n",
            "mortified\n",
            "mown\n",
            "mudded\n",
            "muddied\n",
            "mudding\n",
            "mugged\n",
            "mugging\n",
            "multiplied\n",
            "mummed\n",
            "mummified\n",
            "mumming\n",
            "mutinied\n",
            "mystified\n",
            "nabbed\n",
            "nabbing\n",
            "nagged\n",
            "nagging\n",
            "napped\n",
            "napping\n",
            "netted\n",
            "netting\n",
            "nibbed\n",
            "nibbing\n",
            "nickelled\n",
            "nickelling\n",
            "nid-nodded\n",
            "nid-nodding\n",
            "nidified\n",
            "nigrified\n",
            "nipped\n",
            "nipping\n",
            "nitrified\n",
            "nodded\n",
            "nodding\n",
            "non-prossed\n",
            "non-prosses\n",
            "non-prossing\n",
            "nonplussed\n",
            "nonplusses\n",
            "nonplussing\n",
            "notified\n",
            "nullified\n",
            "nutted\n",
            "nutting\n",
            "objectified\n",
            "occupied\n",
            "occurred\n",
            "occurring\n",
            "offsetting\n",
            "omitted\n",
            "omitting\n",
            "ossified\n",
            "outbidden\n",
            "outbidding\n",
            "outbred\n",
            "outcried\n",
            "outcropped\n",
            "outcropping\n",
            "outdid\n",
            "outdone\n",
            "outdrawn\n",
            "outdrew\n",
            "outfitted\n",
            "outfitting\n",
            "outfought\n",
            "outgassed\n",
            "outgasses\n",
            "outgassing\n",
            "outgeneralled\n",
            "outgeneralling\n",
            "outgone\n",
            "outgrew\n",
            "outgrown\n",
            "outlaid\n",
            "outmanned\n",
            "outmanning\n",
            "outputted\n",
            "outputting\n",
            "outran\n",
            "outridden\n",
            "outrode\n",
            "outrunning\n",
            "outshone\n",
            "outshot\n",
            "outsold\n",
            "outspanned\n",
            "outspanning\n",
            "outstood\n",
            "outstripped\n",
            "outstripping\n",
            "outthought\n",
            "outwent\n",
            "outwitted\n",
            "outwitting\n",
            "outwore\n",
            "outworn\n",
            "overbidden\n",
            "overbidding\n",
            "overblew\n",
            "overblown\n",
            "overbore\n",
            "overborne\n",
            "overbuilt\n",
            "overcame\n",
            "overcropped\n",
            "overcropping\n",
            "overdid\n",
            "overdone\n",
            "overdrawn\n",
            "overdrew\n",
            "overdriven\n",
            "overdrove\n",
            "overflew\n",
            "overflown\n",
            "overgrew\n",
            "overgrown\n",
            "overheard\n",
            "overhung\n",
            "overlaid\n",
            "overlain\n",
            "overlapped\n",
            "overlapping\n",
            "overlay\n",
            "overlying\n",
            "overmanned\n",
            "overmanning\n",
            "overpaid\n",
            "overpast\n",
            "overran\n",
            "overridden\n",
            "overrode\n",
            "overrunning\n",
            "oversaw\n",
            "overseen\n",
            "oversetting\n",
            "oversewn\n",
            "overshot\n",
            "oversimplified\n",
            "overslept\n",
            "oversold\n",
            "overspent\n",
            "overspilt\n",
            "overstepped\n",
            "overstepping\n",
            "overtaken\n",
            "overthrew\n",
            "overthrown\n",
            "overtook\n",
            "overtopped\n",
            "overtopping\n",
            "overwound\n",
            "overwritten\n",
            "overwrote\n",
            "pacified\n",
            "padded\n",
            "padding\n",
            "paid\n",
            "palled\n",
            "palling\n",
            "palsied\n",
            "pandied\n",
            "panelled\n",
            "panelling\n",
            "panicked\n",
            "panicking\n",
            "panned\n",
            "panning\n",
            "parallelled\n",
            "parallelling\n",
            "parcelled\n",
            "parcelling\n",
            "parodied\n",
            "parried\n",
            "partaken\n",
            "partook\n",
            "pasquil\n",
            "pasquilled\n",
            "pasquilling\n",
            "pasquils\n",
            "patrolled\n",
            "patrolling\n",
            "patted\n",
            "patting\n",
            "pedalled\n",
            "pedalling\n",
            "pegged\n",
            "pegging\n",
            "pencilled\n",
            "pencilling\n",
            "penned\n",
            "penning\n",
            "pent\n",
            "pepped\n",
            "pepping\n",
            "permitted\n",
            "permitting\n",
            "personified\n",
            "petrified\n",
            "petted\n",
            "pettifogged\n",
            "pettifogging\n",
            "petting\n",
            "phantasied\n",
            "photocopied\n",
            "photomapped\n",
            "photomapping\n",
            "photosetting\n",
            "physicked\n",
            "physicking\n",
            "picnicked\n",
            "picnicking\n",
            "pigged\n",
            "pigging\n",
            "pilloried\n",
            "pinch-hitting\n",
            "pinned\n",
            "pinning\n",
            "pipped\n",
            "pipping\n",
            "pistol-whipped\n",
            "pistol-whipping\n",
            "pistolled\n",
            "pistolling\n",
            "pitapatted\n",
            "pitapatting\n",
            "pitied\n",
            "pitted\n",
            "pitting\n",
            "planned\n",
            "planning\n",
            "platted\n",
            "platting\n",
            "played_a_part\n",
            "playing_a_part\n",
            "plays_a_part\n",
            "pled\n",
            "plied\n",
            "plodded\n",
            "plodding\n",
            "plopped\n",
            "plopping\n",
            "plotted\n",
            "plotting\n",
            "plugged\n",
            "plugging\n",
            "podded\n",
            "podding\n",
            "pommelled\n",
            "pommelling\n",
            "popes\n",
            "popped\n",
            "popping\n",
            "potted\n",
            "potting\n",
            "preachified\n",
            "precancelled\n",
            "precancelling\n",
            "preferred\n",
            "preferring\n",
            "preoccupied\n",
            "prepaid\n",
            "presignified\n",
            "pretermitted\n",
            "pretermitting\n",
            "prettied\n",
            "prettified\n",
            "pried\n",
            "prigged\n",
            "prigging\n",
            "primmed\n",
            "primming\n",
            "prodded\n",
            "prodding\n",
            "programmed\n",
            "programmes\n",
            "programming\n",
            "prologed\n",
            "prologing\n",
            "prologs\n",
            "propelled\n",
            "propelling\n",
            "prophesied\n",
            "propped\n",
            "propping\n",
            "proven\n",
            "pubbed\n",
            "pubbing\n",
            "pugged\n",
            "pugging\n",
            "pummelled\n",
            "pummelling\n",
            "punned\n",
            "punning\n",
            "pupped\n",
            "pupping\n",
            "purified\n",
            "put-putted\n",
            "put-putting\n",
            "putrefied\n",
            "puttied\n",
            "putting\n",
            "qualified\n",
            "quantified\n",
            "quarrelled\n",
            "quarrelling\n",
            "quarried\n",
            "quartersawn\n",
            "queried\n",
            "quick-froze\n",
            "quick-frozen\n",
            "quickstepped\n",
            "quickstepping\n",
            "quipped\n",
            "quipping\n",
            "quitted\n",
            "quitting\n",
            "quizzed\n",
            "quizzes\n",
            "quizzing\n",
            "ragged\n",
            "ragging\n",
            "rallied\n",
            "ramified\n",
            "rammed\n",
            "ramming\n",
            "ran\n",
            "rang\n",
            "rapped\n",
            "rappelled\n",
            "rappelling\n",
            "rapping\n",
            "rarefied\n",
            "ratified\n",
            "ratted\n",
            "ratting\n",
            "ravelled\n",
            "ravelling\n",
            "razor-cutting\n",
            "re-trod\n",
            "re-trodden\n",
            "rebelled\n",
            "rebelling\n",
            "rebuilt\n",
            "rebutted\n",
            "rebutting\n",
            "recapped\n",
            "recapping\n",
            "reclassified\n",
            "recommitted\n",
            "recommitting\n",
            "recopied\n",
            "rectified\n",
            "recurred\n",
            "recurring\n",
            "red\n",
            "red-pencilled\n",
            "red-pencilling\n",
            "redded\n",
            "redding\n",
            "redid\n",
            "redone\n",
            "referred\n",
            "referring\n",
            "refitted\n",
            "refitting\n",
            "reft\n",
            "refuelled\n",
            "refuelling\n",
            "regretted\n",
            "regretting\n",
            "reheard\n",
            "reified\n",
            "relied\n",
            "remade\n",
            "remarried\n",
            "remitted\n",
            "remitting\n",
            "rent\n",
            "repaid\n",
            "repelled\n",
            "repelling\n",
            "replevied\n",
            "replied\n",
            "repotted\n",
            "repotting\n",
            "reran\n",
            "rerunning\n",
            "resat\n",
            "resetting\n",
            "resewn\n",
            "resitting\n",
            "retaken\n",
            "rethought\n",
            "retold\n",
            "retook\n",
            "retransmitted\n",
            "retransmitting\n",
            "retried\n",
            "retrofitted\n",
            "retrofitting\n",
            "retted\n",
            "retting\n",
            "reunified\n",
            "revelled\n",
            "revelling\n",
            "revetted\n",
            "revetting\n",
            "revivified\n",
            "revved\n",
            "revving\n",
            "rewound\n",
            "rewritten\n",
            "rewrote\n",
            "ribbed\n",
            "ribbing\n",
            "ricochetted\n",
            "ricochetting\n",
            "ridded\n",
            "ridden\n",
            "ridding\n",
            "rigged\n",
            "rigging\n",
            "rigidified\n",
            "rimmed\n",
            "rimming\n",
            "ripped\n",
            "ripping\n",
            "risen\n",
            "rivalled\n",
            "rivalling\n",
            "riven\n",
            "robbed\n",
            "robbing\n",
            "rode\n",
            "rose\n",
            "rotted\n",
            "rotting\n",
            "rough-dried\n",
            "rough-hewn\n",
            "rove\n",
            "rowelled\n",
            "rowelling\n",
            "rubbed\n",
            "rubbing\n",
            "rung\n",
            "running\n",
            "rutted\n",
            "rutting\n",
            "saccharified\n",
            "sagged\n",
            "sagging\n",
            "said\n",
            "salaried\n",
            "salified\n",
            "sallied\n",
            "sanctified\n",
            "sandbagged\n",
            "sandbagging\n",
            "sang\n",
            "sank\n",
            "saponified\n",
            "sapped\n",
            "sapping\n",
            "sat\n",
            "satisfied\n",
            "savvied\n",
            "saw\n",
            "sawn\n",
            "scagged\n",
            "scagging\n",
            "scanned\n",
            "scanning\n",
            "scarified\n",
            "scarred\n",
            "scarring\n",
            "scatted\n",
            "scatting\n",
            "scorified\n",
            "scragged\n",
            "scragging\n",
            "scrammed\n",
            "scramming\n",
            "scrapped\n",
            "scrapping\n",
            "scried\n",
            "scrubbed\n",
            "scrubbing\n",
            "scrummed\n",
            "scrumming\n",
            "scudded\n",
            "scudding\n",
            "scummed\n",
            "scumming\n",
            "scurried\n",
            "seed\n",
            "seen\n",
            "sent\n",
            "setting\n",
            "sewn\n",
            "shagged\n",
            "shagging\n",
            "shaken\n",
            "shaken_hands\n",
            "shakes_hands\n",
            "shaking_hands\n",
            "shammed\n",
            "shamming\n",
            "sharecropped\n",
            "sharecropping\n",
            "shat\n",
            "shaven\n",
            "shed\n",
            "shedding\n",
            "shellacked\n",
            "shellacking\n",
            "shent\n",
            "shewn\n",
            "shied\n",
            "shikarred\n",
            "shikarring\n",
            "shillyshallied\n",
            "shimmed\n",
            "shimmied\n",
            "shimming\n",
            "shinned\n",
            "shinning\n",
            "shipped\n",
            "shipping\n",
            "shitted\n",
            "shitting\n",
            "shod\n",
            "shone\n",
            "shook\n",
            "shook_hands\n",
            "shopped\n",
            "shopping\n",
            "shot\n",
            "shotgunned\n",
            "shotgunning\n",
            "shotted\n",
            "shotting\n",
            "shovelled\n",
            "shovelling\n",
            "shown\n",
            "shrank\n",
            "shredded\n",
            "shredding\n",
            "shrink-wrapped\n",
            "shrink-wrapping\n",
            "shrivelled\n",
            "shrivelling\n",
            "shriven\n",
            "shrove\n",
            "shrugged\n",
            "shrugging\n",
            "shrunk\n",
            "shrunken\n",
            "shunned\n",
            "shunning\n",
            "shutting\n",
            "sicked\n",
            "sicking\n",
            "sideslipped\n",
            "sideslipping\n",
            "sidestepped\n",
            "sidestepping\n",
            "sightsaw\n",
            "sightseen\n",
            "signalled\n",
            "signalling\n",
            "signified\n",
            "silicified\n",
            "simplified\n",
            "singing\n",
            "single-stepped\n",
            "single-stepping\n",
            "sinned\n",
            "sinning\n",
            "sipped\n",
            "sipping\n",
            "sitting\n",
            "skellied\n",
            "skenned\n",
            "skenning\n",
            "sketted\n",
            "sketting\n",
            "ski'd\n",
            "skidded\n",
            "skidding\n",
            "skimmed\n",
            "skimming\n",
            "skin-popped\n",
            "skin-popping\n",
            "skinned\n",
            "skinning\n",
            "skinny-dipped\n",
            "skinny-dipping\n",
            "skipped\n",
            "skipping\n",
            "skivvied\n",
            "skydove\n",
            "slabbed\n",
            "slabbing\n",
            "slagged\n",
            "slagging\n",
            "slain\n",
            "slammed\n",
            "slamming\n",
            "slapped\n",
            "slapping\n",
            "slatted\n",
            "slatting\n",
            "sledding\n",
            "slept\n",
            "slew\n",
            "slid\n",
            "slidden\n",
            "slipped\n",
            "slipping\n",
            "slitting\n",
            "slogged\n",
            "slogging\n",
            "slopped\n",
            "slopping\n",
            "slotted\n",
            "slotting\n",
            "slugged\n",
            "slugging\n",
            "slummed\n",
            "slumming\n",
            "slung\n",
            "slunk\n",
            "slurred\n",
            "slurring\n",
            "smelt\n",
            "smit\n",
            "smitten\n",
            "smote\n",
            "smutted\n",
            "smutting\n",
            "snagged\n",
            "snagging\n",
            "snapped\n",
            "snapping\n",
            "snedded\n",
            "snedding\n",
            "snipped\n",
            "snipping\n",
            "snivelled\n",
            "snivelling\n",
            "snogged\n",
            "snogging\n",
            "snubbed\n",
            "snubbing\n",
            "snuck\n",
            "snugged\n",
            "snugging\n",
            "sobbed\n",
            "sobbing\n",
            "sodded\n",
            "sodding\n",
            "soft-pedalled\n",
            "soft-pedalling\n",
            "sold\n",
            "solemnified\n",
            "solidified\n",
            "soothsaid\n",
            "sopped\n",
            "sopping\n",
            "sought\n",
            "sown\n",
            "spagged\n",
            "spagging\n",
            "spancelled\n",
            "spancelling\n",
            "spanned\n",
            "spanning\n",
            "sparred\n",
            "sparring\n",
            "spat\n",
            "spatted\n",
            "spatting\n",
            "specified\n",
            "sped\n",
            "speechified\n",
            "spellbound\n",
            "spelt\n",
            "spent\n",
            "spied\n",
            "spilt\n",
            "spin-dried\n",
            "spinning\n",
            "spiralled\n",
            "spiralling\n",
            "spitted\n",
            "spitting\n",
            "splitting\n",
            "spoilt\n",
            "spoke\n",
            "spoken\n",
            "spoon-fed\n",
            "spotlit\n",
            "spotted\n",
            "spotting\n",
            "sprang\n",
            "sprigged\n",
            "sprigging\n",
            "sprung\n",
            "spudded\n",
            "spudding\n",
            "spun\n",
            "spurred\n",
            "spurring\n",
            "squatted\n",
            "squatting\n",
            "squibbed\n",
            "squibbing\n",
            "squidded\n",
            "squidding\n",
            "squilgee\n",
            "stabbed\n",
            "stabbing\n",
            "stall-fed\n",
            "stank\n",
            "starred\n",
            "starring\n",
            "steadied\n",
            "stellified\n",
            "stemmed\n",
            "stemming\n",
            "stems_from\n",
            "stencilled\n",
            "stencilling\n",
            "stepped\n",
            "stepping\n",
            "stetted\n",
            "stetting\n",
            "stied\n",
            "stilettoeing\n",
            "stirred\n",
            "stirring\n",
            "stole\n",
            "stolen\n",
            "stood\n",
            "stopped\n",
            "stopping\n",
            "storied\n",
            "stotted\n",
            "stotting\n",
            "stove\n",
            "strapped\n",
            "strapping\n",
            "stratified\n",
            "strewn\n",
            "stridden\n",
            "stripped\n",
            "stripping\n",
            "striven\n",
            "strode\n",
            "stropped\n",
            "stropping\n",
            "strove\n",
            "strown\n",
            "struck\n",
            "strummed\n",
            "strumming\n",
            "strung\n",
            "strutted\n",
            "strutting\n",
            "stubbed\n",
            "stubbing\n",
            "stuck\n",
            "studded\n",
            "studding\n",
            "studied\n",
            "stultified\n",
            "stummed\n",
            "stumming\n",
            "stung\n",
            "stunk\n",
            "stunned\n",
            "stunning\n",
            "stupefied\n",
            "stymying\n",
            "subbed\n",
            "subbing\n",
            "subjectified\n",
            "subletting\n",
            "submitted\n",
            "submitting\n",
            "subtotalled\n",
            "subtotalling\n",
            "sullied\n",
            "sulphuretted\n",
            "sulphuretting\n",
            "summed\n",
            "summing\n",
            "sung\n",
            "sunk\n",
            "sunken\n",
            "sunned\n",
            "sunning\n",
            "supped\n",
            "supping\n",
            "supplied\n",
            "swabbed\n",
            "swabbing\n",
            "swagged\n",
            "swagging\n",
            "swam\n",
            "swapped\n",
            "swapping\n",
            "swatted\n",
            "swatting\n",
            "swept\n",
            "swigged\n",
            "swigging\n",
            "swimming\n",
            "swivelled\n",
            "swivelling\n",
            "swollen\n",
            "swopped\n",
            "swopping\n",
            "swops\n",
            "swore\n",
            "sworn\n",
            "swotted\n",
            "swotting\n",
            "swum\n",
            "swung\n",
            "syllabified\n",
            "symbolled\n",
            "symbolling\n",
            "tabbed\n",
            "tabbing\n",
            "tagged\n",
            "tagging\n",
            "taken\n",
            "taken_a_side\n",
            "taken_pains\n",
            "taken_steps\n",
            "takes_a_side\n",
            "takes_pains\n",
            "takes_steps\n",
            "taking_a_side\n",
            "taking_pains\n",
            "taking_steps\n",
            "talcked\n",
            "talcking\n",
            "tallied\n",
            "tally-ho'd\n",
            "tammied\n",
            "tanned\n",
            "tanning\n",
            "tapped\n",
            "tapping\n",
            "tarred\n",
            "tarried\n",
            "tarring\n",
            "tasselled\n",
            "tasselling\n",
            "tatted\n",
            "tatting\n",
            "taught\n",
            "taxis\n",
            "taxying\n",
            "teaselled\n",
            "teaselling\n",
            "tedded\n",
            "tedding\n",
            "tepefied\n",
            "terrified\n",
            "testes\n",
            "testified\n",
            "thinking_the_world_of\n",
            "thinks_the_world_of\n",
            "thinned\n",
            "thinning\n",
            "thought\n",
            "thought_the_world_of\n",
            "threw\n",
            "threw_out\n",
            "thriven\n",
            "throbbed\n",
            "throbbing\n",
            "throve\n",
            "throwing_out\n",
            "thrown\n",
            "thrown_out\n",
            "throws_out\n",
            "thrummed\n",
            "thrumming\n",
            "thudded\n",
            "thudding\n",
            "tidied\n",
            "tinned\n",
            "tinning\n",
            "tinselled\n",
            "tinselling\n",
            "tipped\n",
            "tipping\n",
            "tittupped\n",
            "tittupping\n",
            "toadied\n",
            "togged\n",
            "togging\n",
            "told\n",
            "took\n",
            "took_a_side\n",
            "took_pains\n",
            "took_steps\n",
            "topped\n",
            "topping\n",
            "tore\n",
            "torn\n",
            "torrefied\n",
            "torrify\n",
            "totalled\n",
            "totalling\n",
            "totted\n",
            "totting\n",
            "towelled\n",
            "towelling\n",
            "trafficked\n",
            "trafficking\n",
            "trameled\n",
            "trameling\n",
            "tramelled\n",
            "tramelling\n",
            "tramels\n",
            "trammed\n",
            "tramming\n",
            "transferred\n",
            "transferring\n",
            "transfixt\n",
            "tranship\n",
            "transhipped\n",
            "transhipping\n",
            "transmitted\n",
            "transmitting\n",
            "transmogrified\n",
            "transshipped\n",
            "transshipping\n",
            "trapanned\n",
            "trapanning\n",
            "trapped\n",
            "trapping\n",
            "travelled\n",
            "travelling\n",
            "travestied\n",
            "trekked\n",
            "trekking\n",
            "trepanned\n",
            "trepanning\n",
            "tried\n",
            "trigged\n",
            "trigging\n",
            "trimmed\n",
            "trimming\n",
            "tripped\n",
            "tripping\n",
            "trod\n",
            "trodden\n",
            "trogged\n",
            "trogging\n",
            "trotted\n",
            "trotting\n",
            "trowelled\n",
            "trowelling\n",
            "tugged\n",
            "tugging\n",
            "tumefied\n",
            "tunned\n",
            "tunnelled\n",
            "tunnelling\n",
            "tunning\n",
            "tupped\n",
            "tupping\n",
            "tut-tutted\n",
            "tut-tutting\n",
            "twigged\n",
            "twigging\n",
            "twinned\n",
            "twinning\n",
            "twitted\n",
            "twitting\n",
            "tying\n",
            "typesetting\n",
            "typewritten\n",
            "typewrote\n",
            "typified\n",
            "uglified\n",
            "unbarred\n",
            "unbarring\n",
            "unbent\n",
            "unbound\n",
            "uncapped\n",
            "uncapping\n",
            "unclad\n",
            "unclogged\n",
            "unclogging\n",
            "underbidding\n",
            "underbought\n",
            "undercutting\n",
            "underfed\n",
            "undergirt\n",
            "undergone\n",
            "underlaid\n",
            "underlain\n",
            "underlay\n",
            "underletting\n",
            "underlying\n",
            "underpaid\n",
            "underpinned\n",
            "underpinning\n",
            "underpropped\n",
            "underpropping\n",
            "undersetting\n",
            "undershot\n",
            "undersold\n",
            "understood\n",
            "understudied\n",
            "undertaken\n",
            "undertook\n",
            "underwent\n",
            "underwritten\n",
            "underwrote\n",
            "undid\n",
            "undone\n",
            "unfitted\n",
            "unfitting\n",
            "unfroze\n",
            "unfrozen\n",
            "unified\n",
            "unkennelled\n",
            "unkennelling\n",
            "unknitted\n",
            "unknitting\n",
            "unlaid\n",
            "unlearnt\n",
            "unmade\n",
            "unmanned\n",
            "unmanning\n",
            "unpegged\n",
            "unpegging\n",
            "unpinned\n",
            "unpinning\n",
            "unplugged\n",
            "unplugging\n",
            "unravelled\n",
            "unravelling\n",
            "unrigged\n",
            "unrigging\n",
            "unripped\n",
            "unripping\n",
            "unrove\n",
            "unsaid\n",
            "unshipped\n",
            "unshipping\n",
            "unslung\n",
            "unsnapped\n",
            "unsnapping\n",
            "unspoke\n",
            "unspoken\n",
            "unsteadied\n",
            "unstepped\n",
            "unstepping\n",
            "unstopped\n",
            "unstopping\n",
            "unstrung\n",
            "unstuck\n",
            "unswore\n",
            "unsworn\n",
            "untaught\n",
            "unthought\n",
            "untidied\n",
            "untrod\n",
            "untrodden\n",
            "untying\n",
            "unwound\n",
            "unwrapped\n",
            "unwrapping\n",
            "unzipped\n",
            "unzipping\n",
            "upbuilt\n",
            "upheld\n",
            "uphove\n",
            "upped\n",
            "uppercutting\n",
            "upping\n",
            "uprisen\n",
            "uprose\n",
            "upsetting\n",
            "upsprang\n",
            "upsprung\n",
            "upswept\n",
            "upswollen\n",
            "upswung\n",
            "vagged\n",
            "vagging\n",
            "varied\n",
            "vatted\n",
            "vatting\n",
            "verbified\n",
            "verified\n",
            "versified\n",
            "vetted\n",
            "vetting\n",
            "victualled\n",
            "victualling\n",
            "vilified\n",
            "vitrified\n",
            "vitriolled\n",
            "vitriolling\n",
            "vivified\n",
            "vying\n",
            "wadded\n",
            "waddied\n",
            "wadding\n",
            "wadsetted\n",
            "wadsetting\n",
            "wagged\n",
            "wagging\n",
            "wanned\n",
            "wanning\n",
            "warred\n",
            "warring\n",
            "was\n",
            "water-ski'd\n",
            "waylaid\n",
            "wearied\n",
            "weatherstripped\n",
            "weatherstripping\n",
            "webbed\n",
            "webbing\n",
            "wedded\n",
            "wedding\n",
            "weed\n",
            "went\n",
            "went_deep\n",
            "wept\n",
            "were\n",
            "wetted\n",
            "wetting\n",
            "whammed\n",
            "whamming\n",
            "whapped\n",
            "whapping\n",
            "whetted\n",
            "whetting\n",
            "whinnied\n",
            "whipped\n",
            "whipping\n",
            "whipsawn\n",
            "whirred\n",
            "whirring\n",
            "whistle-stopped\n",
            "whistle-stopping\n",
            "whizzed\n",
            "whizzes\n",
            "whizzing\n",
            "whopped\n",
            "whopping\n",
            "wigged\n",
            "wigging\n",
            "wigwagged\n",
            "wigwagging\n",
            "wildcatted\n",
            "wildcatting\n",
            "window-shopped\n",
            "window-shopping\n",
            "winning\n",
            "winterfed\n",
            "wiredrawn\n",
            "wiredrew\n",
            "withdrawn\n",
            "withdrew\n",
            "withheld\n",
            "withstood\n",
            "woke\n",
            "woken\n",
            "won\n",
            "wonned\n",
            "wonning\n",
            "wore\n",
            "worn\n",
            "worried\n",
            "worshipped\n",
            "worshipping\n",
            "wound\n",
            "wove\n",
            "woven\n",
            "wrapped\n",
            "wrapping\n",
            "wried\n",
            "written\n",
            "wrote\n",
            "wrought\n",
            "wrung\n",
            "yakked\n",
            "yakking\n",
            "yapped\n",
            "yapping\n",
            "ycleped\n",
            "yclept\n",
            "yenned\n",
            "yenning\n",
            "yodelled\n",
            "yodelling\n",
            "zapped\n",
            "zapping\n",
            "zigzagged\n",
            "zigzagging\n",
            "zipped\n",
            "zipping\n",
            "adj.exc\n",
            "acer\n",
            "after\n",
            "airier\n",
            "airiest\n",
            "all-arounder\n",
            "angrier\n",
            "angriest\n",
            "archer\n",
            "artier\n",
            "artiest\n",
            "ashier\n",
            "ashiest\n",
            "assaulter\n",
            "attacker\n",
            "backer\n",
            "baggier\n",
            "baggiest\n",
            "balkier\n",
            "balkiest\n",
            "balmier\n",
            "balmiest\n",
            "bandier\n",
            "bandiest\n",
            "bargainer\n",
            "barmier\n",
            "barmiest\n",
            "battier\n",
            "battiest\n",
            "baulkier\n",
            "baulkiest\n",
            "bawdier\n",
            "bawdiest\n",
            "bayer\n",
            "beadier\n",
            "beadiest\n",
            "beastlier\n",
            "beastliest\n",
            "beater\n",
            "beefier\n",
            "beefiest\n",
            "beerier\n",
            "beeriest\n",
            "bendier\n",
            "bendiest\n",
            "best\n",
            "better\n",
            "bigger\n",
            "biggest\n",
            "bitchier\n",
            "bitchiest\n",
            "biter\n",
            "bittier\n",
            "bittiest\n",
            "blearier\n",
            "bleariest\n",
            "bloodier\n",
            "bloodiest\n",
            "bloodthirstier\n",
            "bloodthirstiest\n",
            "blowier\n",
            "blowiest\n",
            "blowsier\n",
            "blowsiest\n",
            "blowzier\n",
            "blowziest\n",
            "bluer\n",
            "bluest\n",
            "boner\n",
            "bonier\n",
            "boniest\n",
            "bonnier\n",
            "bonniest\n",
            "boozier\n",
            "booziest\n",
            "boskier\n",
            "boskiest\n",
            "bossier\n",
            "bossiest\n",
            "botchier\n",
            "botchiest\n",
            "bother\n",
            "bouncier\n",
            "bounciest\n",
            "bounder\n",
            "bower\n",
            "brainier\n",
            "brainiest\n",
            "brashier\n",
            "brashiest\n",
            "brassier\n",
            "brassiest\n",
            "brawnier\n",
            "brawniest\n",
            "breathier\n",
            "breathiest\n",
            "breezier\n",
            "breeziest\n",
            "brinier\n",
            "briniest\n",
            "britisher\n",
            "broadcaster\n",
            "brooder\n",
            "broodier\n",
            "broodiest\n",
            "bubblier\n",
            "bubbliest\n",
            "buggier\n",
            "buggiest\n",
            "bulkier\n",
            "bulkiest\n",
            "bumpier\n",
            "bumpiest\n",
            "bunchier\n",
            "bunchiest\n",
            "burlier\n",
            "burliest\n",
            "burrier\n",
            "burriest\n",
            "burster\n",
            "bushier\n",
            "bushiest\n",
            "busier\n",
            "busiest\n",
            "buster\n",
            "bustier\n",
            "bustiest\n",
            "cagier\n",
            "cagiest\n",
            "camper\n",
            "cannier\n",
            "canniest\n",
            "canter\n",
            "cantier\n",
            "cantiest\n",
            "caster\n",
            "catchier\n",
            "catchiest\n",
            "cattier\n",
            "cattiest\n",
            "cer\n",
            "chancier\n",
            "chanciest\n",
            "charier\n",
            "chariest\n",
            "chattier\n",
            "chattiest\n",
            "cheekier\n",
            "cheekiest\n",
            "cheerier\n",
            "cheeriest\n",
            "cheesier\n",
            "cheesiest\n",
            "chestier\n",
            "chestiest\n",
            "chewier\n",
            "chewiest\n",
            "chillier\n",
            "chilliest\n",
            "chintzier\n",
            "chintziest\n",
            "chippier\n",
            "chippiest\n",
            "choosier\n",
            "choosiest\n",
            "choppier\n",
            "choppiest\n",
            "chubbier\n",
            "chubbiest\n",
            "chuffier\n",
            "chuffiest\n",
            "chummier\n",
            "chummiest\n",
            "chunkier\n",
            "chunkiest\n",
            "churchier\n",
            "churchiest\n",
            "clammier\n",
            "clammiest\n",
            "classier\n",
            "classiest\n",
            "cleanlier\n",
            "cleanliest\n",
            "clerklier\n",
            "clerkliest\n",
            "cloudier\n",
            "cloudiest\n",
            "clubbier\n",
            "clubbiest\n",
            "clumsier\n",
            "clumsiest\n",
            "cockier\n",
            "cockiest\n",
            "coder\n",
            "collier\n",
            "colliest\n",
            "comelier\n",
            "comeliest\n",
            "comfier\n",
            "comfiest\n",
            "cornier\n",
            "corniest\n",
            "cosier\n",
            "cosiest\n",
            "costlier\n",
            "costliest\n",
            "costumer\n",
            "counterfeiter\n",
            "courtlier\n",
            "courtliest\n",
            "cozier\n",
            "coziest\n",
            "crabbier\n",
            "crabbiest\n",
            "cracker\n",
            "craftier\n",
            "craftiest\n",
            "craggier\n",
            "craggiest\n",
            "crankier\n",
            "crankiest\n",
            "crasher\n",
            "crawlier\n",
            "crawliest\n",
            "crazier\n",
            "craziest\n",
            "creamer\n",
            "creamier\n",
            "creamiest\n",
            "creepier\n",
            "creepiest\n",
            "crispier\n",
            "crispiest\n",
            "crumbier\n",
            "crumbiest\n",
            "crumblier\n",
            "crumbliest\n",
            "crummier\n",
            "crummiest\n",
            "crustier\n",
            "crustiest\n",
            "curlier\n",
            "curliest\n",
            "customer\n",
            "cuter\n",
            "daffier\n",
            "daffiest\n",
            "daintier\n",
            "daintiest\n",
            "dandier\n",
            "dandiest\n",
            "deadlier\n",
            "deadliest\n",
            "dealer\n",
            "deserter\n",
            "dewier\n",
            "dewiest\n",
            "dicier\n",
            "diciest\n",
            "dimer\n",
            "dimmer\n",
            "dimmest\n",
            "dingier\n",
            "dingiest\n",
            "dinkier\n",
            "dinkiest\n",
            "dippier\n",
            "dippiest\n",
            "dirtier\n",
            "dirtiest\n",
            "dishier\n",
            "dishiest\n",
            "dizzier\n",
            "dizziest\n",
            "dodgier\n",
            "dodgiest\n",
            "dopier\n",
            "dopiest\n",
            "dottier\n",
            "dottiest\n",
            "doughier\n",
            "doughiest\n",
            "doughtier\n",
            "doughtiest\n",
            "dowdier\n",
            "dowdiest\n",
            "dowier\n",
            "dowiest\n",
            "downer\n",
            "downier\n",
            "downiest\n",
            "dozier\n",
            "doziest\n",
            "drabber\n",
            "drabbest\n",
            "draftier\n",
            "draftiest\n",
            "draggier\n",
            "draggiest\n",
            "draughtier\n",
            "draughtiest\n",
            "dreamier\n",
            "dreamiest\n",
            "drearier\n",
            "dreariest\n",
            "dreggier\n",
            "dreggiest\n",
            "dresser\n",
            "dressier\n",
            "dressiest\n",
            "drier\n",
            "driest\n",
            "drippier\n",
            "drippiest\n",
            "drowsier\n",
            "drowsiest\n",
            "dryer\n",
            "dryest\n",
            "dumpier\n",
            "dumpiest\n",
            "dunner\n",
            "dunnest\n",
            "duskier\n",
            "duskiest\n",
            "dustier\n",
            "dustiest\n",
            "earlier\n",
            "earliest\n",
            "earthier\n",
            "earthiest\n",
            "earthlier\n",
            "earthliest\n",
            "easier\n",
            "easiest\n",
            "easter\n",
            "eastsider\n",
            "edger\n",
            "edgier\n",
            "edgiest\n",
            "eerier\n",
            "eeriest\n",
            "emptier\n",
            "emptiest\n",
            "faker\n",
            "fancier\n",
            "fanciest\n",
            "fatter\n",
            "fattest\n",
            "fattier\n",
            "fattiest\n",
            "faultier\n",
            "faultiest\n",
            "feistier\n",
            "feistiest\n",
            "feller\n",
            "fiddlier\n",
            "fiddliest\n",
            "filmier\n",
            "filmiest\n",
            "filthier\n",
            "filthiest\n",
            "finnier\n",
            "finniest\n",
            "first-rater\n",
            "first-stringer\n",
            "fishier\n",
            "fishiest\n",
            "fitter\n",
            "fittest\n",
            "flabbier\n",
            "flabbiest\n",
            "flaggier\n",
            "flaggiest\n",
            "flakier\n",
            "flakiest\n",
            "flasher\n",
            "flashier\n",
            "flashiest\n",
            "flatter\n",
            "flattest\n",
            "flauntier\n",
            "flauntiest\n",
            "fledgier\n",
            "fledgiest\n",
            "fleecier\n",
            "fleeciest\n",
            "fleshier\n",
            "fleshiest\n",
            "fleshlier\n",
            "fleshliest\n",
            "flightier\n",
            "flightiest\n",
            "flimsier\n",
            "flimsiest\n",
            "flintier\n",
            "flintiest\n",
            "floatier\n",
            "floatiest\n",
            "floppier\n",
            "floppiest\n",
            "flossier\n",
            "flossiest\n",
            "fluffier\n",
            "fluffiest\n",
            "flukier\n",
            "flukiest\n",
            "foamier\n",
            "foamiest\n",
            "foggier\n",
            "foggiest\n",
            "folder\n",
            "folksier\n",
            "folksiest\n",
            "foolhardier\n",
            "foolhardiest\n",
            "fore-and-after\n",
            "foreigner\n",
            "forest\n",
            "founder\n",
            "foxier\n",
            "foxiest\n",
            "fratchier\n",
            "fratchiest\n",
            "freakier\n",
            "freakiest\n",
            "freer\n",
            "freest\n",
            "frenchier\n",
            "frenchiest\n",
            "friendlier\n",
            "friendliest\n",
            "friskier\n",
            "friskiest\n",
            "frizzier\n",
            "frizziest\n",
            "frizzlier\n",
            "frizzliest\n",
            "frostier\n",
            "frostiest\n",
            "frouzier\n",
            "frouziest\n",
            "frowsier\n",
            "frowsiest\n",
            "frowzier\n",
            "frowziest\n",
            "fruitier\n",
            "fruitiest\n",
            "funkier\n",
            "funkiest\n",
            "funnier\n",
            "funniest\n",
            "furrier\n",
            "furriest\n",
            "fussier\n",
            "fussiest\n",
            "fustier\n",
            "fustiest\n",
            "fuzzier\n",
            "fuzziest\n",
            "gabbier\n",
            "gabbiest\n",
            "gamier\n",
            "gamiest\n",
            "gammier\n",
            "gammiest\n",
            "gassier\n",
            "gassiest\n",
            "gaudier\n",
            "gaudiest\n",
            "gauzier\n",
            "gauziest\n",
            "gawkier\n",
            "gawkiest\n",
            "ghastlier\n",
            "ghastliest\n",
            "ghostlier\n",
            "ghostliest\n",
            "giddier\n",
            "giddiest\n",
            "gladder\n",
            "gladdest\n",
            "glassier\n",
            "glassiest\n",
            "glibber\n",
            "glibbest\n",
            "gloomier\n",
            "gloomiest\n",
            "glossier\n",
            "glossiest\n",
            "glummer\n",
            "glummest\n",
            "godlier\n",
            "godliest\n",
            "goer\n",
            "goner\n",
            "goodlier\n",
            "goodliest\n",
            "goofier\n",
            "goofiest\n",
            "gooier\n",
            "gooiest\n",
            "goosier\n",
            "goosiest\n",
            "gorier\n",
            "goriest\n",
            "gradelier\n",
            "gradeliest\n",
            "grader\n",
            "grainier\n",
            "grainiest\n",
            "grassier\n",
            "grassiest\n",
            "greasier\n",
            "greasiest\n",
            "greedier\n",
            "greediest\n",
            "grimmer\n",
            "grimmest\n",
            "grislier\n",
            "grisliest\n",
            "grittier\n",
            "grittiest\n",
            "grizzlier\n",
            "grizzliest\n",
            "groggier\n",
            "groggiest\n",
            "groovier\n",
            "grooviest\n",
            "grottier\n",
            "grottiest\n",
            "grounder\n",
            "grouper\n",
            "groutier\n",
            "groutiest\n",
            "grubbier\n",
            "grubbiest\n",
            "grumpier\n",
            "grumpiest\n",
            "guest\n",
            "guiltier\n",
            "guiltiest\n",
            "gummier\n",
            "gummiest\n",
            "gushier\n",
            "gushiest\n",
            "gustier\n",
            "gustiest\n",
            "gutsier\n",
            "gutsiest\n",
            "hairier\n",
            "hairiest\n",
            "halfways\n",
            "halter\n",
            "hammier\n",
            "hammiest\n",
            "handier\n",
            "handiest\n",
            "happier\n",
            "happiest\n",
            "hardier\n",
            "hardiest\n",
            "hastier\n",
            "hastiest\n",
            "haughtier\n",
            "haughtiest\n",
            "hazier\n",
            "haziest\n",
            "header\n",
            "headier\n",
            "headiest\n",
            "healthier\n",
            "healthiest\n",
            "heartier\n",
            "heartiest\n",
            "heavier\n",
            "heaviest\n",
            "heftier\n",
            "heftiest\n",
            "hepper\n",
            "heppest\n",
            "herbier\n",
            "herbiest\n",
            "hinder\n",
            "hipper\n",
            "hippest\n",
            "hippier\n",
            "hippiest\n",
            "hoarier\n",
            "hoariest\n",
            "holier\n",
            "holiest\n",
            "homelier\n",
            "homeliest\n",
            "homer\n",
            "homier\n",
            "homiest\n",
            "hornier\n",
            "horniest\n",
            "horsier\n",
            "horsiest\n",
            "hotter\n",
            "hottest\n",
            "humpier\n",
            "humpiest\n",
            "hunger\n",
            "hungrier\n",
            "hungriest\n",
            "huskier\n",
            "huskiest\n",
            "icier\n",
            "iciest\n",
            "inkier\n",
            "inkiest\n",
            "insider\n",
            "interest\n",
            "jaggier\n",
            "jaggiest\n",
            "jammier\n",
            "jammiest\n",
            "jauntier\n",
            "jauntiest\n",
            "jazzier\n",
            "jazziest\n",
            "jerkier\n",
            "jerkiest\n",
            "jointer\n",
            "jollier\n",
            "jolliest\n",
            "juicier\n",
            "juiciest\n",
            "jumpier\n",
            "jumpiest\n",
            "kindlier\n",
            "kindliest\n",
            "kinkier\n",
            "kinkiest\n",
            "knottier\n",
            "knottiest\n",
            "knurlier\n",
            "knurliest\n",
            "kookier\n",
            "kookiest\n",
            "lacier\n",
            "laciest\n",
            "lairier\n",
            "lairiest\n",
            "lakier\n",
            "lakiest\n",
            "lander\n",
            "lankier\n",
            "lankiest\n",
            "lathier\n",
            "lathiest\n",
            "layer\n",
            "lazier\n",
            "laziest\n",
            "leafier\n",
            "leafiest\n",
            "leakier\n",
            "leakiest\n",
            "learier\n",
            "leariest\n",
            "leer\n",
            "leerier\n",
            "leeriest\n",
            "left-hander\n",
            "left-winger\n",
            "leggier\n",
            "leggiest\n",
            "lengthier\n",
            "lengthiest\n",
            "ler\n",
            "leveler\n",
            "limier\n",
            "limiest\n",
            "lippier\n",
            "lippiest\n",
            "liter\n",
            "livelier\n",
            "liveliest\n",
            "liver\n",
            "loather\n",
            "loftier\n",
            "loftiest\n",
            "logier\n",
            "logiest\n",
            "lonelier\n",
            "loneliest\n",
            "loner\n",
            "loonier\n",
            "looniest\n",
            "loopier\n",
            "loopiest\n",
            "lordlier\n",
            "lordliest\n",
            "lousier\n",
            "lousiest\n",
            "lovelier\n",
            "loveliest\n",
            "lowlander\n",
            "lowlier\n",
            "lowliest\n",
            "luckier\n",
            "luckiest\n",
            "lumpier\n",
            "lumpiest\n",
            "lunier\n",
            "luniest\n",
            "lustier\n",
            "lustiest\n",
            "madder\n",
            "maddest\n",
            "mainer\n",
            "maligner\n",
            "maltier\n",
            "maltiest\n",
            "mangier\n",
            "mangiest\n",
            "mankier\n",
            "mankiest\n",
            "manlier\n",
            "manliest\n",
            "mariner\n",
            "marshier\n",
            "marshiest\n",
            "massier\n",
            "massiest\n",
            "matter\n",
            "maungier\n",
            "maungiest\n",
            "mazier\n",
            "maziest\n",
            "mealier\n",
            "mealiest\n",
            "measlier\n",
            "measliest\n",
            "meatier\n",
            "meatiest\n",
            "meeter\n",
            "merrier\n",
            "merriest\n",
            "messier\n",
            "messiest\n",
            "miffier\n",
            "miffiest\n",
            "mightier\n",
            "mightiest\n",
            "milcher\n",
            "milker\n",
            "milkier\n",
            "milkiest\n",
            "mingier\n",
            "mingiest\n",
            "minter\n",
            "mirkier\n",
            "mirkiest\n",
            "miser\n",
            "mistier\n",
            "mistiest\n",
            "mocker\n",
            "modeler\n",
            "modest\n",
            "moldier\n",
            "moldiest\n",
            "moodier\n",
            "moodiest\n",
            "moonier\n",
            "mooniest\n",
            "mothier\n",
            "mothiest\n",
            "mouldier\n",
            "mouldiest\n",
            "mousier\n",
            "mousiest\n",
            "mouthier\n",
            "mouthiest\n",
            "muckier\n",
            "muckiest\n",
            "muddier\n",
            "muddiest\n",
            "muggier\n",
            "muggiest\n",
            "multiplexer\n",
            "murkier\n",
            "murkiest\n",
            "mushier\n",
            "mushiest\n",
            "muskier\n",
            "muskiest\n",
            "muster\n",
            "mustier\n",
            "mustiest\n",
            "muzzier\n",
            "muzziest\n",
            "nappier\n",
            "nappiest\n",
            "nastier\n",
            "nastiest\n",
            "nattier\n",
            "nattiest\n",
            "naughtier\n",
            "naughtiest\n",
            "needier\n",
            "neediest\n",
            "nervier\n",
            "nerviest\n",
            "newsier\n",
            "newsiest\n",
            "niftier\n",
            "niftiest\n",
            "nippier\n",
            "nippiest\n",
            "nittier\n",
            "nittiest\n",
            "noisier\n",
            "noisiest\n",
            "northeasterner\n",
            "norther\n",
            "northerner\n",
            "nosier\n",
            "nosiest\n",
            "number\n",
            "nuttier\n",
            "nuttiest\n",
            "offer\n",
            "offer\n",
            "oilier\n",
            "oiliest\n",
            "old-timer\n",
            "oliver\n",
            "oozier\n",
            "ooziest\n",
            "opener\n",
            "outsider\n",
            "overcomer\n",
            "overnighter\n",
            "owner\n",
            "pallier\n",
            "palliest\n",
            "palmier\n",
            "palmiest\n",
            "paltrier\n",
            "paltriest\n",
            "pappier\n",
            "pappiest\n",
            "parkier\n",
            "parkiest\n",
            "part-timer\n",
            "passer\n",
            "paster\n",
            "pastier\n",
            "pastiest\n",
            "patchier\n",
            "patchiest\n",
            "pater\n",
            "pawkier\n",
            "pawkiest\n",
            "peachier\n",
            "peachiest\n",
            "pearler\n",
            "pearlier\n",
            "pearliest\n",
            "pedaler\n",
            "peppier\n",
            "peppiest\n",
            "perkier\n",
            "perkiest\n",
            "peskier\n",
            "peskiest\n",
            "peter\n",
            "pettier\n",
            "pettiest\n",
            "phonier\n",
            "phoniest\n",
            "pickier\n",
            "pickiest\n",
            "piggier\n",
            "piggiest\n",
            "pinier\n",
            "piniest\n",
            "pitchier\n",
            "pitchiest\n",
            "pithier\n",
            "pithiest\n",
            "planer\n",
            "plashier\n",
            "plashiest\n",
            "platier\n",
            "platiest\n",
            "player\n",
            "pluckier\n",
            "pluckiest\n",
            "plumber\n",
            "plumier\n",
            "plumiest\n",
            "plummier\n",
            "plummiest\n",
            "podgier\n",
            "podgiest\n",
            "pokier\n",
            "pokiest\n",
            "polisher\n",
            "porkier\n",
            "porkiest\n",
            "porter\n",
            "portlier\n",
            "portliest\n",
            "poster\n",
            "pottier\n",
            "pottiest\n",
            "preachier\n",
            "preachiest\n",
            "presenter\n",
            "pretender\n",
            "prettier\n",
            "prettiest\n",
            "pricier\n",
            "priciest\n",
            "pricklier\n",
            "prickliest\n",
            "priestlier\n",
            "priestliest\n",
            "primer\n",
            "primmer\n",
            "primmest\n",
            "princelier\n",
            "princeliest\n",
            "printer\n",
            "prissier\n",
            "prissiest\n",
            "privateer\n",
            "privier\n",
            "priviest\n",
            "prompter\n",
            "prosier\n",
            "prosiest\n",
            "pudgier\n",
            "pudgiest\n",
            "puffer\n",
            "puffier\n",
            "puffiest\n",
            "pulpier\n",
            "pulpiest\n",
            "punchier\n",
            "punchiest\n",
            "punier\n",
            "puniest\n",
            "pushier\n",
            "pushiest\n",
            "pussier\n",
            "pussiest\n",
            "quaggier\n",
            "quaggiest\n",
            "quakier\n",
            "quakiest\n",
            "queasier\n",
            "queasiest\n",
            "queenlier\n",
            "queenliest\n",
            "racier\n",
            "raciest\n",
            "rainier\n",
            "rainiest\n",
            "randier\n",
            "randiest\n",
            "rangier\n",
            "rangiest\n",
            "ranker\n",
            "rattier\n",
            "rattiest\n",
            "rattlier\n",
            "rattliest\n",
            "raunchier\n",
            "raunchiest\n",
            "readier\n",
            "readiest\n",
            "recorder\n",
            "redder\n",
            "reddest\n",
            "reedier\n",
            "reediest\n",
            "renter\n",
            "retailer\n",
            "right-hander\n",
            "right-winger\n",
            "rimier\n",
            "rimiest\n",
            "riskier\n",
            "riskiest\n",
            "ritzier\n",
            "ritziest\n",
            "roaster\n",
            "rockier\n",
            "rockiest\n",
            "roilier\n",
            "roiliest\n",
            "rookier\n",
            "rookiest\n",
            "roomier\n",
            "roomiest\n",
            "ropier\n",
            "ropiest\n",
            "rosier\n",
            "rosiest\n",
            "rowdier\n",
            "rowdiest\n",
            "ruddier\n",
            "ruddiest\n",
            "runnier\n",
            "runniest\n",
            "rusher\n",
            "rushier\n",
            "rushiest\n",
            "rustier\n",
            "rustiest\n",
            "ruttier\n",
            "ruttiest\n",
            "sadder\n",
            "saddest\n",
            "salter\n",
            "saltier\n",
            "saltiest\n",
            "sampler\n",
            "sandier\n",
            "sandiest\n",
            "sappier\n",
            "sappiest\n",
            "sassier\n",
            "sassiest\n",
            "saucier\n",
            "sauciest\n",
            "savvier\n",
            "savviest\n",
            "scabbier\n",
            "scabbiest\n",
            "scalier\n",
            "scaliest\n",
            "scantier\n",
            "scantiest\n",
            "scarier\n",
            "scariest\n",
            "scraggier\n",
            "scraggiest\n",
            "scragglier\n",
            "scraggliest\n",
            "scraper\n",
            "scrappier\n",
            "scrappiest\n",
            "scrawnier\n",
            "scrawniest\n",
            "screwier\n",
            "screwiest\n",
            "scrubbier\n",
            "scrubbiest\n",
            "scruffier\n",
            "scruffiest\n",
            "scungier\n",
            "scungiest\n",
            "scurvier\n",
            "scurviest\n",
            "seamier\n",
            "seamiest\n",
            "second-rater\n",
            "seconder\n",
            "seedier\n",
            "seediest\n",
            "seemlier\n",
            "seemliest\n",
            "serer\n",
            "sexier\n",
            "sexiest\n",
            "shabbier\n",
            "shabbiest\n",
            "shadier\n",
            "shadiest\n",
            "shaggier\n",
            "shaggiest\n",
            "shakier\n",
            "shakiest\n",
            "shapelier\n",
            "shapeliest\n",
            "shier\n",
            "shiest\n",
            "shiftier\n",
            "shiftiest\n",
            "shinier\n",
            "shiniest\n",
            "shirtier\n",
            "shirtiest\n",
            "shoddier\n",
            "shoddiest\n",
            "showier\n",
            "showiest\n",
            "shrubbier\n",
            "shrubbiest\n",
            "shyer\n",
            "shyest\n",
            "sicklier\n",
            "sickliest\n",
            "sightlier\n",
            "sightliest\n",
            "signaler\n",
            "signer\n",
            "silkier\n",
            "silkiest\n",
            "sillier\n",
            "silliest\n",
            "sketchier\n",
            "sketchiest\n",
            "skewer\n",
            "skimpier\n",
            "skimpiest\n",
            "skinnier\n",
            "skinniest\n",
            "slaphappier\n",
            "slaphappiest\n",
            "slatier\n",
            "slatiest\n",
            "slaver\n",
            "sleazier\n",
            "sleaziest\n",
            "sleepier\n",
            "sleepiest\n",
            "slier\n",
            "sliest\n",
            "slimier\n",
            "slimiest\n",
            "slimmer\n",
            "slimmest\n",
            "slimsier\n",
            "slimsiest\n",
            "slinkier\n",
            "slinkiest\n",
            "slippier\n",
            "slippiest\n",
            "sloppier\n",
            "sloppiest\n",
            "slyer\n",
            "slyest\n",
            "smarmier\n",
            "smarmiest\n",
            "smellier\n",
            "smelliest\n",
            "smokier\n",
            "smokiest\n",
            "smugger\n",
            "smuggest\n",
            "snakier\n",
            "snakiest\n",
            "snappier\n",
            "snappiest\n",
            "snatchier\n",
            "snatchiest\n",
            "snazzier\n",
            "snazziest\n",
            "sneaker\n",
            "sniffier\n",
            "sniffiest\n",
            "snootier\n",
            "snootiest\n",
            "snottier\n",
            "snottiest\n",
            "snowier\n",
            "snowiest\n",
            "snuffer\n",
            "snuffier\n",
            "snuffiest\n",
            "snugger\n",
            "snuggest\n",
            "soapier\n",
            "soapiest\n",
            "soggier\n",
            "soggiest\n",
            "solder\n",
            "sonsier\n",
            "sonsiest\n",
            "sootier\n",
            "sootiest\n",
            "soppier\n",
            "soppiest\n",
            "sorrier\n",
            "sorriest\n",
            "soupier\n",
            "soupiest\n",
            "souther\n",
            "southerner\n",
            "speedier\n",
            "speediest\n",
            "spicier\n",
            "spiciest\n",
            "spiffier\n",
            "spiffiest\n",
            "spikier\n",
            "spikiest\n",
            "spindlier\n",
            "spindliest\n",
            "spinier\n",
            "spiniest\n",
            "splashier\n",
            "splashiest\n",
            "spongier\n",
            "spongiest\n",
            "spookier\n",
            "spookiest\n",
            "spoonier\n",
            "spooniest\n",
            "sportier\n",
            "sportiest\n",
            "spottier\n",
            "spottiest\n",
            "spreader\n",
            "sprier\n",
            "spriest\n",
            "sprightlier\n",
            "sprightliest\n",
            "springer\n",
            "springier\n",
            "springiest\n",
            "squashier\n",
            "squashiest\n",
            "squatter\n",
            "squattest\n",
            "squattier\n",
            "squattiest\n",
            "squiffier\n",
            "squiffiest\n",
            "stagier\n",
            "stagiest\n",
            "stalkier\n",
            "stalkiest\n",
            "stapler\n",
            "starchier\n",
            "starchiest\n",
            "starer\n",
            "starest\n",
            "starrier\n",
            "starriest\n",
            "statelier\n",
            "stateliest\n",
            "steadier\n",
            "steadiest\n",
            "stealthier\n",
            "stealthiest\n",
            "steamier\n",
            "steamiest\n",
            "stingier\n",
            "stingiest\n",
            "stiper\n",
            "stocker\n",
            "stockier\n",
            "stockiest\n",
            "stodgier\n",
            "stodgiest\n",
            "stonier\n",
            "stoniest\n",
            "stormier\n",
            "stormiest\n",
            "streakier\n",
            "streakiest\n",
            "streamier\n",
            "streamiest\n",
            "stretcher\n",
            "stretchier\n",
            "stretchiest\n",
            "stringier\n",
            "stringiest\n",
            "stripier\n",
            "stripiest\n",
            "stronger\n",
            "strongest\n",
            "stroppier\n",
            "stroppiest\n",
            "stuffier\n",
            "stuffiest\n",
            "stumpier\n",
            "stumpiest\n",
            "sturdier\n",
            "sturdiest\n",
            "submariner\n",
            "sulkier\n",
            "sulkiest\n",
            "sultrier\n",
            "sultriest\n",
            "sunnier\n",
            "sunniest\n",
            "surlier\n",
            "surliest\n",
            "swagger\n",
            "swankier\n",
            "swankiest\n",
            "swarthier\n",
            "swarthiest\n",
            "sweatier\n",
            "sweatiest\n",
            "tackier\n",
            "tackiest\n",
            "talkier\n",
            "talkiest\n",
            "tangier\n",
            "tangiest\n",
            "tanner\n",
            "tannest\n",
            "tardier\n",
            "tardiest\n",
            "tastier\n",
            "tastiest\n",
            "tattier\n",
            "tattiest\n",
            "tawdrier\n",
            "tawdriest\n",
            "techier\n",
            "techiest\n",
            "teenager\n",
            "teenier\n",
            "teeniest\n",
            "teetotaler\n",
            "tester\n",
            "testier\n",
            "testiest\n",
            "tetchier\n",
            "tetchiest\n",
            "thinner\n",
            "thinnest\n",
            "third-rater\n",
            "thirstier\n",
            "thirstiest\n",
            "thornier\n",
            "thorniest\n",
            "threadier\n",
            "threadiest\n",
            "thriftier\n",
            "thriftiest\n",
            "throatier\n",
            "throatiest\n",
            "tidier\n",
            "tidiest\n",
            "timelier\n",
            "timeliest\n",
            "tinier\n",
            "tiniest\n",
            "tinnier\n",
            "tinniest\n",
            "tipsier\n",
            "tipsiest\n",
            "tonier\n",
            "toniest\n",
            "toothier\n",
            "toothiest\n",
            "toper\n",
            "touchier\n",
            "touchiest\n",
            "trader\n",
            "trashier\n",
            "trashiest\n",
            "trendier\n",
            "trendiest\n",
            "trickier\n",
            "trickiest\n",
            "tricksier\n",
            "tricksiest\n",
            "trimer\n",
            "trimmer\n",
            "trimmest\n",
            "truer\n",
            "truest\n",
            "trustier\n",
            "trustiest\n",
            "tubbier\n",
            "tubbiest\n",
            "turfier\n",
            "turfiest\n",
            "tweedier\n",
            "tweediest\n",
            "twiggier\n",
            "twiggiest\n",
            "uglier\n",
            "ugliest\n",
            "unfriendlier\n",
            "unfriendliest\n",
            "ungainlier\n",
            "ungainliest\n",
            "ungodlier\n",
            "ungodliest\n",
            "unhappier\n",
            "unhappiest\n",
            "unhealthier\n",
            "unhealthiest\n",
            "unholier\n",
            "unholiest\n",
            "unrulier\n",
            "unruliest\n",
            "untidier\n",
            "untidiest\n",
            "vastier\n",
            "vastiest\n",
            "vest\n",
            "viewier\n",
            "viewiest\n",
            "wackier\n",
            "wackiest\n",
            "wanner\n",
            "wannest\n",
            "warier\n",
            "wariest\n",
            "washier\n",
            "washiest\n",
            "waster\n",
            "wavier\n",
            "waviest\n",
            "waxier\n",
            "waxiest\n",
            "weaklier\n",
            "weakliest\n",
            "wealthier\n",
            "wealthiest\n",
            "wearier\n",
            "weariest\n",
            "webbier\n",
            "webbiest\n",
            "weedier\n",
            "weediest\n",
            "weenier\n",
            "weeniest\n",
            "weensier\n",
            "weensiest\n",
            "weepier\n",
            "weepiest\n",
            "weightier\n",
            "weightiest\n",
            "welsher\n",
            "wetter\n",
            "wettest\n",
            "whackier\n",
            "whackiest\n",
            "whimsier\n",
            "whimsiest\n",
            "wholesaler\n",
            "wieldier\n",
            "wieldiest\n",
            "wilier\n",
            "wiliest\n",
            "windier\n",
            "windiest\n",
            "winier\n",
            "winiest\n",
            "winterier\n",
            "winteriest\n",
            "wintrier\n",
            "wintriest\n",
            "wirier\n",
            "wiriest\n",
            "wispier\n",
            "wispiest\n",
            "wittier\n",
            "wittiest\n",
            "wonkier\n",
            "wonkiest\n",
            "woodier\n",
            "woodiest\n",
            "woodsier\n",
            "woodsiest\n",
            "woollier\n",
            "woolliest\n",
            "woozier\n",
            "wooziest\n",
            "wordier\n",
            "wordiest\n",
            "worldlier\n",
            "worldliest\n",
            "wormier\n",
            "wormiest\n",
            "worse\n",
            "worst\n",
            "worthier\n",
            "worthiest\n",
            "wrier\n",
            "wriest\n",
            "wryer\n",
            "wryest\n",
            "yarer\n",
            "yarest\n",
            "yeastier\n",
            "yeastiest\n",
            "younger\n",
            "youngest\n",
            "yummier\n",
            "yummiest\n",
            "zanier\n",
            "zaniest\n",
            "zippier\n",
            "zippiest\n",
            "noun.exc\n",
            "aardwolves\n",
            "abaci\n",
            "aboideaux\n",
            "aboiteaux\n",
            "abscissae\n",
            "acanthi\n",
            "acari\n",
            "acciaccature\n",
            "acetabula\n",
            "achaemenidae\n",
            "achaemenides\n",
            "acicula\n",
            "aciculae\n",
            "acini\n",
            "acre-feet\n",
            "acromia\n",
            "actiniae\n",
            "actinozoa\n",
            "addenda\n",
            "adenocarcinomata\n",
            "adenomata\n",
            "adieux\n",
            "adyta\n",
            "aecia\n",
            "aecidia\n",
            "aerobia\n",
            "agents-general\n",
            "aggiornamenti\n",
            "agnomina\n",
            "agones\n",
            "agorae\n",
            "agouties\n",
            "aides-de-camp\n",
            "aides-memoire\n",
            "aids-de-camp\n",
            "alae\n",
            "alewives\n",
            "alkalies\n",
            "allodia\n",
            "alluvia\n",
            "alodia\n",
            "alto-relievos\n",
            "altocumuli\n",
            "altostrati\n",
            "alulae\n",
            "alumnae\n",
            "alumni\n",
            "alveoli\n",
            "amanuenses\n",
            "ambulacra\n",
            "amebae\n",
            "amici_curiae\n",
            "amnia\n",
            "amniocenteses\n",
            "amoebae\n",
            "amoebiases\n",
            "amoraim\n",
            "amoretti\n",
            "amorini\n",
            "amphiarthroses\n",
            "amphicia\n",
            "amphimixes\n",
            "amphioxi\n",
            "amphisbaenae\n",
            "amphorae\n",
            "ampullae\n",
            "amygdalae\n",
            "anabases\n",
            "anacolutha\n",
            "anacruses\n",
            "anaerobia\n",
            "anagnorises\n",
            "analemmata\n",
            "analyses\n",
            "anamneses\n",
            "anamorphoses\n",
            "anastomoses\n",
            "anatyxes\n",
            "ancones\n",
            "androclinia\n",
            "androecia\n",
            "androsphinges\n",
            "andtheridia\n",
            "angelfishes\n",
            "angiomata\n",
            "animalcula\n",
            "anlagen\n",
            "annattos\n",
            "annuli\n",
            "antae\n",
            "antalkalies\n",
            "antefixa\n",
            "antennae\n",
            "antependia\n",
            "anthelia\n",
            "anthelices\n",
            "anthemia\n",
            "antheridia\n",
            "anthodia\n",
            "anthozoa\n",
            "anthraces\n",
            "anticlinoria\n",
            "antihelices\n",
            "antiheroes\n",
            "antisera\n",
            "antitheses\n",
            "antitragi\n",
            "antra\n",
            "anus\n",
            "aortae\n",
            "aphelia\n",
            "aphides\n",
            "apices\n",
            "apodoses\n",
            "apomixes\n",
            "aponeuroses\n",
            "apophyses\n",
            "aposiopeses\n",
            "apothecia\n",
            "apotheoses\n",
            "apparatus\n",
            "appendices\n",
            "appoggiature\n",
            "apsides\n",
            "aquae\n",
            "aquaria\n",
            "araglis\n",
            "arboreta\n",
            "arcana\n",
            "archegonia\n",
            "archerfishes\n",
            "archesporia\n",
            "archipelagoes\n",
            "arcs-boutants\n",
            "areolae\n",
            "argali\n",
            "argumenta\n",
            "ariette\n",
            "aristae\n",
            "armamentaria\n",
            "arses\n",
            "artal\n",
            "artel\n",
            "arterioscleroses\n",
            "aruspices\n",
            "asceses\n",
            "asci\n",
            "ascidia\n",
            "ascogonia\n",
            "ashkenazim\n",
            "aspergilla\n",
            "aspergilli\n",
            "aspergilloses\n",
            "aspersoria\n",
            "assegais\n",
            "astragali\n",
            "asyndeta\n",
            "atheromata\n",
            "atheroscleroses\n",
            "atmolyses\n",
            "atria\n",
            "attorneys-at-law\n",
            "auditoria\n",
            "aurae\n",
            "aurar\n",
            "aurei\n",
            "auriculae\n",
            "aurorae\n",
            "auspices\n",
            "autocatalyses\n",
            "autochthones\n",
            "automata\n",
            "autos-da-fe\n",
            "avitaminoses\n",
            "axes\n",
            "axillae\n",
            "bacchantes\n",
            "bacchii\n",
            "bacilli\n",
            "bacteriostases\n",
            "bacula\n",
            "bains-marie\n",
            "bains_marie\n",
            "ballistae\n",
            "bambini\n",
            "bandeaux\n",
            "banditti\n",
            "bani\n",
            "banjoes\n",
            "barklice\n",
            "barramundies\n",
            "bases\n",
            "bases-on-balls\n",
            "bases_on_balls\n",
            "basidia\n",
            "basileis\n",
            "bassi\n",
            "bastinadoes\n",
            "bateaux\n",
            "batfishes\n",
            "beadsmen\n",
            "beaux\n",
            "beches-de-mer\n",
            "beeves\n",
            "behooves\n",
            "bersaglieri\n",
            "bhishties\n",
            "bibliothecae\n",
            "bicennaries\n",
            "bijoux\n",
            "bilboes\n",
            "billets-doux\n",
            "billfishes\n",
            "bimboes\n",
            "bisectrices\n",
            "blackfeet\n",
            "blackfishes\n",
            "blastemata\n",
            "blastulae\n",
            "blindfishes\n",
            "blowfishes\n",
            "bluefishes\n",
            "boarfishes\n",
            "bok\n",
            "boleti\n",
            "bolivares\n",
            "bolsheviki\n",
            "bonefishes\n",
            "bongoes\n",
            "bonitoes\n",
            "booklice\n",
            "bookshelves\n",
            "boraces\n",
            "borborygmi\n",
            "bordereaux\n",
            "botargoes\n",
            "box-kodaks\n",
            "boxfishes\n",
            "brachia\n",
            "brainchildren\n",
            "branchiae\n",
            "brants\n",
            "bravadoes\n",
            "bravoes\n",
            "bregmata\n",
            "brethren\n",
            "broadcast_media\n",
            "broadleaves\n",
            "bronchi\n",
            "brothers-in-law\n",
            "bryozoa\n",
            "buboes\n",
            "buckoes\n",
            "buckteeth\n",
            "buffaloes\n",
            "bullae\n",
            "bunde\n",
            "bureaux\n",
            "bureaux_de_change\n",
            "bursae\n",
            "bushbok\n",
            "bushboks\n",
            "busses\n",
            "butterfishes\n",
            "byssi\n",
            "cacti\n",
            "caducei\n",
            "caeca\n",
            "caesurae\n",
            "calami\n",
            "calathi\n",
            "calcanei\n",
            "calces\n",
            "calculi\n",
            "caldaria\n",
            "calices\n",
            "calicoes\n",
            "calli\n",
            "calves\n",
            "calyces\n",
            "cambia\n",
            "camerae\n",
            "canaliculi\n",
            "candelabra\n",
            "candlefishes\n",
            "canthi\n",
            "canulae\n",
            "canzoni\n",
            "capita\n",
            "capitula\n",
            "capricci\n",
            "carabinieri\n",
            "carbonadoes\n",
            "carcinomata\n",
            "cargoes\n",
            "carides\n",
            "carinae\n",
            "caroli\n",
            "carpi\n",
            "carpogonia\n",
            "carryings-on\n",
            "caryopses\n",
            "caryopsides\n",
            "castrati\n",
            "catabases\n",
            "cataclases\n",
            "cataloes\n",
            "catalyses\n",
            "catenae\n",
            "catfishes\n",
            "cathari\n",
            "cathexes\n",
            "cattaloes\n",
            "caudices\n",
            "caules\n",
            "cavatine\n",
            "cavefishes\n",
            "cavetti\n",
            "cavo-rilievi\n",
            "ceca\n",
            "cellae\n",
            "cembali\n",
            "centesimi\n",
            "centra\n",
            "cephalothoraces\n",
            "cercariae\n",
            "cercariiae\n",
            "cerci\n",
            "cerebella\n",
            "cerebra\n",
            "cervices\n",
            "cestuses\n",
            "cesurae\n",
            "chadarim\n",
            "chaetae\n",
            "chaises_longues\n",
            "chalazae\n",
            "challoth\n",
            "chalutzim\n",
            "chapaties\n",
            "chapatties\n",
            "chapeaux\n",
            "chasidim\n",
            "chassidim\n",
            "chateaux\n",
            "chazanim\n",
            "chedarim\n",
            "chefs-d'ouvre\n",
            "chelae\n",
            "chelicerae\n",
            "cherubim\n",
            "chevaux-de-frise\n",
            "chiasmata\n",
            "chiasmi\n",
            "children\n",
            "chillies\n",
            "chinese_eddoes\n",
            "chitarroni\n",
            "chlamydes\n",
            "chlamyses\n",
            "chondromata\n",
            "choragi\n",
            "choriambi\n",
            "choux\n",
            "chromonemata\n",
            "chrysalides\n",
            "chuvashes\n",
            "ciboria\n",
            "cicadae\n",
            "cicale\n",
            "cicatrices\n",
            "ciceroni\n",
            "cicisbei\n",
            "cilia\n",
            "cimices\n",
            "cineraria\n",
            "cingula\n",
            "cirri\n",
            "cirrocumuli\n",
            "cirrostrati\n",
            "ciscoes\n",
            "cisternae\n",
            "clani\n",
            "clanos\n",
            "claroes\n",
            "clepsydrae\n",
            "clinandria\n",
            "clingfishes\n",
            "clitella\n",
            "cloacae\n",
            "clostridia\n",
            "cloverleaves\n",
            "clypei\n",
            "coagula\n",
            "coalfishes\n",
            "cocci\n",
            "coccyges\n",
            "cochleae\n",
            "codfishes\n",
            "codices\n",
            "coelentera\n",
            "coenuri\n",
            "cognomina\n",
            "cola\n",
            "coleorhizae\n",
            "collegia\n",
            "colloquia\n",
            "colluvia\n",
            "collyria\n",
            "colones\n",
            "colossi\n",
            "columbaria\n",
            "columellae\n",
            "comae\n",
            "comatulae\n",
            "comedones\n",
            "comics\n",
            "commandoes\n",
            "concertanti\n",
            "concerti\n",
            "concerti_grossi\n",
            "concertini\n",
            "conchae\n",
            "condottieri\n",
            "condylomata\n",
            "confervae\n",
            "congii\n",
            "conidia\n",
            "conjunctivae\n",
            "conquistadores\n",
            "consortia\n",
            "contagia\n",
            "continua\n",
            "contralti\n",
            "conversazioni\n",
            "convolvuli\n",
            "cooks-general\n",
            "copulae\n",
            "corbiculae\n",
            "coria\n",
            "corneae\n",
            "cornua\n",
            "coronae\n",
            "corpora\n",
            "corpora_lutea\n",
            "corpora_striata\n",
            "corrigenda\n",
            "cortices\n",
            "cortinae\n",
            "corybantes\n",
            "coryphaei\n",
            "costae\n",
            "cothurni\n",
            "courts_martial\n",
            "couteaux\n",
            "cowfishes\n",
            "coxae\n",
            "cramboes\n",
            "crania\n",
            "crases\n",
            "crawfishes\n",
            "crayfishes\n",
            "credenda\n",
            "crematoria\n",
            "crescendi\n",
            "cribella\n",
            "crises\n",
            "crissa\n",
            "cristae\n",
            "criteria\n",
            "cruces\n",
            "crura\n",
            "crusadoes\n",
            "cruzadoes\n",
            "crying\n",
            "cryings\n",
            "ctenidia\n",
            "cubicula\n",
            "culices\n",
            "culpae\n",
            "culs-de-sac\n",
            "culti\n",
            "cumuli\n",
            "cumulonimbi\n",
            "cumulostrati\n",
            "curiae\n",
            "curricula\n",
            "custodes\n",
            "cutes\n",
            "cuticulae\n",
            "cuttlefishes\n",
            "cyclopes\n",
            "cycloses\n",
            "cylices\n",
            "cylikes\n",
            "cymae\n",
            "cymatia\n",
            "cypselae\n",
            "cysticerci\n",
            "dadoes\n",
            "dagoes\n",
            "damselfishes\n",
            "data\n",
            "daughters-in-law\n",
            "daymio\n",
            "daymios\n",
            "dealfishes\n",
            "decemviri\n",
            "decennia\n",
            "deciduae\n",
            "definienda\n",
            "definientia\n",
            "delphinia\n",
            "denarii\n",
            "dentalia\n",
            "dermatoses\n",
            "desiderata\n",
            "desperadoes\n",
            "devilfishes\n",
            "diaereses\n",
            "diaerses\n",
            "diagnoses\n",
            "dialyses\n",
            "diaphyses\n",
            "diapophyses\n",
            "diarthroses\n",
            "diastalses\n",
            "diastases\n",
            "diastemata\n",
            "diathses\n",
            "diazoes\n",
            "dibbukkim\n",
            "dichasia\n",
            "dicta\n",
            "didoes\n",
            "diereses\n",
            "dieses\n",
            "differentiae\n",
            "dilettanti\n",
            "diluvia\n",
            "dingoes\n",
            "diplococci\n",
            "directors-general\n",
            "disci\n",
            "discoboli\n",
            "dive\n",
            "diverticula\n",
            "divertimenti\n",
            "djinn\n",
            "dodoes\n",
            "dogfishes\n",
            "dogmata\n",
            "dogteeth\n",
            "dollarfishes\n",
            "domatia\n",
            "dominoes\n",
            "dormice\n",
            "dorsa\n",
            "drachmae\n",
            "drawknives\n",
            "drosophilae\n",
            "drumfishes\n",
            "dryades\n",
            "dui\n",
            "duona\n",
            "duonas\n",
            "dupondii\n",
            "duumviri\n",
            "dwarves\n",
            "dybbukkim\n",
            "ecchymoses\n",
            "ecclesiae\n",
            "ecdyses\n",
            "echidnae\n",
            "echini\n",
            "echinococci\n",
            "echoes\n",
            "ectozoa\n",
            "eddoes\n",
            "edemata\n",
            "effluvia\n",
            "eidola\n",
            "eisegeses\n",
            "eisteddfodau\n",
            "elenchi\n",
            "ellipses\n",
            "eluvia\n",
            "elves\n",
            "elytra\n",
            "embargoes\n",
            "emboli\n",
            "emphases\n",
            "emporia\n",
            "enarthroses\n",
            "encephala\n",
            "encephalitides\n",
            "encephalomata\n",
            "enchiridia\n",
            "enchondromata\n",
            "encomia\n",
            "endamebae\n",
            "endamoebae\n",
            "endocardia\n",
            "endocrania\n",
            "endometria\n",
            "endostea\n",
            "endostoses\n",
            "endothecia\n",
            "endothelia\n",
            "endotheliomata\n",
            "endozoa\n",
            "enemata\n",
            "enneahedra\n",
            "entamebae\n",
            "entamoebae\n",
            "entases\n",
            "entera\n",
            "entia\n",
            "entozoa\n",
            "epencephala\n",
            "epentheses\n",
            "epexegeses\n",
            "ephemera\n",
            "ephemerae\n",
            "ephemerides\n",
            "ephori\n",
            "epicalyces\n",
            "epicanthi\n",
            "epicardia\n",
            "epicedia\n",
            "epicleses\n",
            "epididymides\n",
            "epigastria\n",
            "epiglottides\n",
            "epimysia\n",
            "epiphenomena\n",
            "epiphyses\n",
            "episterna\n",
            "epithalamia\n",
            "epithelia\n",
            "epitheliomata\n",
            "epizoa\n",
            "epyllia\n",
            "equilibria\n",
            "equiseta\n",
            "eringoes\n",
            "errata\n",
            "eryngoes\n",
            "esophagi\n",
            "etyma\n",
            "eucalypti\n",
            "eupatridae\n",
            "euripi\n",
            "exanthemata\n",
            "executrices\n",
            "exegeses\n",
            "exempla\n",
            "exordia\n",
            "exostoses\n",
            "extrema\n",
            "eyeteeth\n",
            "fabliaux\n",
            "faciae\n",
            "faculae\n",
            "faeroese\n",
            "fallfishes\n",
            "famuli\n",
            "farmers-general\n",
            "faroese\n",
            "farragoes\n",
            "fasciae\n",
            "fasciculi\n",
            "fathers-in-law\n",
            "fatsoes\n",
            "faunae\n",
            "feculae\n",
            "fedayeen\n",
            "feet\n",
            "fellaheen\n",
            "fellahin\n",
            "felones_de_se\n",
            "felos_de_se\n",
            "femora\n",
            "fenestellae\n",
            "fenestrae\n",
            "feriae\n",
            "fermate\n",
            "ferulae\n",
            "festschriften\n",
            "fetiales\n",
            "fezzes\n",
            "fiascoes\n",
            "fibrillae\n",
            "fibromata\n",
            "fibulae\n",
            "ficoes\n",
            "fideicommissa\n",
            "fieldmice\n",
            "figs.\n",
            "fila\n",
            "filariiae\n",
            "filefishes\n",
            "fimbriae\n",
            "fishes\n",
            "fishwives\n",
            "fistulae\n",
            "flabella\n",
            "flagella\n",
            "flagstaves\n",
            "flambeaux\n",
            "flamines\n",
            "flamingoes\n",
            "flatfeet\n",
            "flatfishes\n",
            "fleurs-de-lis\n",
            "fleurs-de-lys\n",
            "flights_of_stairs\n",
            "flittermice\n",
            "flocci\n",
            "flocculi\n",
            "florae\n",
            "floreant.\n",
            "florilegia\n",
            "flowers-de-luce\n",
            "flyleaves\n",
            "foci\n",
            "folia\n",
            "fora\n",
            "foramina\n",
            "forceps\n",
            "forefeet\n",
            "foreteeth\n",
            "formicaria\n",
            "formulae\n",
            "fornices\n",
            "fortes\n",
            "fossae\n",
            "foveae\n",
            "foveolae\n",
            "fractocumuli\n",
            "fractostrati\n",
            "fraena\n",
            "frauen\n",
            "frena\n",
            "frenula\n",
            "frescoes\n",
            "fricandeaux\n",
            "fricandoes\n",
            "frijoles\n",
            "frogfishes\n",
            "frontes\n",
            "frusta\n",
            "fuci\n",
            "fulcra\n",
            "fumatoria\n",
            "fundi\n",
            "fungi\n",
            "funiculi\n",
            "furcula\n",
            "furculae\n",
            "furfures\n",
            "galeae\n",
            "gambadoes\n",
            "gametangia\n",
            "gametoecia\n",
            "gammadia\n",
            "ganglia\n",
            "garfishes\n",
            "gas\n",
            "gasses\n",
            "gastrulae\n",
            "gateaux\n",
            "gazeboes\n",
            "geckoes\n",
            "geese\n",
            "gelsemia\n",
            "gemboks\n",
            "gembucks\n",
            "gemeinschaften\n",
            "gemmae\n",
            "genera\n",
            "generatrices\n",
            "geneses\n",
            "genii\n",
            "gentes\n",
            "gentlemen-at-arms\n",
            "gentlemen-farmers\n",
            "genua\n",
            "genus\n",
            "germina\n",
            "gesellschaften\n",
            "gestalten\n",
            "ghettoes\n",
            "gingivae\n",
            "gingkoes\n",
            "ginglymi\n",
            "ginkgoes\n",
            "gippoes\n",
            "glabellae\n",
            "gladioli\n",
            "glandes\n",
            "gliomata\n",
            "glissandi\n",
            "globefishes\n",
            "globigerinae\n",
            "glochidcia\n",
            "glochidia\n",
            "glomeruli\n",
            "glossae\n",
            "glottides\n",
            "glutaei\n",
            "glutei\n",
            "gnoses\n",
            "goatfishes\n",
            "goboes\n",
            "godchildren\n",
            "goes\n",
            "goings-over\n",
            "goldfishes\n",
            "gomphoses\n",
            "gonia\n",
            "gonidia\n",
            "gonococci\n",
            "goodwives\n",
            "goosefishes\n",
            "gorgoneia\n",
            "gospopoda\n",
            "governors_general\n",
            "goyim\n",
            "grafen\n",
            "graffiti\n",
            "grandchildren\n",
            "grants-in-aid\n",
            "granulomata\n",
            "gravamina\n",
            "grig-gris\n",
            "groszy\n",
            "grottoes\n",
            "guilder\n",
            "guilders\n",
            "guitarfishes\n",
            "gummata\n",
            "gurnard\n",
            "gurnards\n",
            "guttae\n",
            "gymnasia\n",
            "gynaecea\n",
            "gynaecia\n",
            "gynecea\n",
            "gynecia\n",
            "gynoecea\n",
            "gynoecia\n",
            "gyri\n",
            "hadarim\n",
            "hadjes\n",
            "haematolyses\n",
            "haematomata\n",
            "haematozoa\n",
            "haemodialyses\n",
            "haemolyses\n",
            "haemoptyses\n",
            "haeredes\n",
            "haftaroth\n",
            "hagfishes\n",
            "haggadas\n",
            "haggadoth\n",
            "hajjes\n",
            "haleru\n",
            "hallot\n",
            "halloth\n",
            "halluces\n",
            "haloes\n",
            "halteres\n",
            "halves\n",
            "hamuli\n",
            "hangers-on\n",
            "haphtaroth\n",
            "haredim\n",
            "haruspices\n",
            "hasidim\n",
            "hassidim\n",
            "haustella\n",
            "haustoria\n",
            "hazzanim\n",
            "hectocotyli\n",
            "heirs-at-law\n",
            "heldentenore\n",
            "helices\n",
            "heliozoa\n",
            "hematolyses\n",
            "hematomata\n",
            "hematozoa\n",
            "hemelytra\n",
            "hemielytra\n",
            "hemodialyses\n",
            "hemolyses\n",
            "hemoptyses\n",
            "hendecahedra\n",
            "hens-and-chickens\n",
            "heraclidae\n",
            "heraklidae\n",
            "herbaria\n",
            "hermae\n",
            "hermai\n",
            "herniae\n",
            "heroes\n",
            "herren\n",
            "hetaerae\n",
            "hetairai\n",
            "hibernacula\n",
            "hieracosphinges\n",
            "hila\n",
            "hili\n",
            "himatia\n",
            "hippocampi\n",
            "hippopotami\n",
            "his\n",
            "hoboes\n",
            "hogfishes\n",
            "homunculi\n",
            "honoraria\n",
            "hooves\n",
            "horologia\n",
            "housewives\n",
            "humeri\n",
            "hydrae\n",
            "hydromedusae\n",
            "hydrozoa\n",
            "hymenoptera\n",
            "hynia\n",
            "hyniums\n",
            "hypanthia\n",
            "hyperostoses\n",
            "hyphae\n",
            "hypnoses\n",
            "hypochondria\n",
            "hypogastria\n",
            "hypogea\n",
            "hypophyses\n",
            "hypostases\n",
            "hypothalami\n",
            "hypotheses\n",
            "hyraces\n",
            "iambi\n",
            "ibices\n",
            "ibo\n",
            "ichthyosauri\n",
            "ichthyosauruses\n",
            "iconostases\n",
            "icosahedra\n",
            "ideata\n",
            "igorrorote\n",
            "ilia\n",
            "imagines\n",
            "imagoes\n",
            "imperia\n",
            "impies\n",
            "incubi\n",
            "incudes\n",
            "indices\n",
            "indigoes\n",
            "indumenta\n",
            "indusia\n",
            "infundibula\n",
            "ingushes\n",
            "innuendoes\n",
            "inocula\n",
            "inquisitors-general\n",
            "insectaria\n",
            "insulae\n",
            "intagli\n",
            "interleaves\n",
            "intermezzi\n",
            "interreges\n",
            "interregna\n",
            "intimae\n",
            "involucella\n",
            "involucra\n",
            "involucra\n",
            "irides\n",
            "irs\n",
            "is\n",
            "ischia\n",
            "isthmi\n",
            "jackeroos\n",
            "jackfishes\n",
            "jackknives\n",
            "jacks-in-the-box\n",
            "jambeaux\n",
            "jellyfishes\n",
            "jewelfishes\n",
            "jewfishes\n",
            "jingoes\n",
            "jinn\n",
            "joes\n",
            "judge_advocates_general\n",
            "jura\n",
            "kaddishim\n",
            "kalmuck\n",
            "kalmucks\n",
            "katabases\n",
            "keeshonden\n",
            "kibbutzim\n",
            "killifishes\n",
            "kingfishes\n",
            "kings-of-arms\n",
            "knights_bachelor\n",
            "knights_bachelors\n",
            "knights_templar\n",
            "knights_templars\n",
            "knives\n",
            "kohlrabies\n",
            "kronen\n",
            "kroner\n",
            "kronur\n",
            "krooni\n",
            "kylikes\n",
            "labara\n",
            "labella\n",
            "labia\n",
            "labra\n",
            "lactobacilli\n",
            "lacunae\n",
            "lacunaria\n",
            "ladies-in-waiting\n",
            "lamellae\n",
            "lamiae\n",
            "laminae\n",
            "lapilli\n",
            "lapithae\n",
            "larvae\n",
            "larynges\n",
            "lassoes\n",
            "lati\n",
            "latices\n",
            "latifundia\n",
            "latu\n",
            "lavaboes\n",
            "leaves\n",
            "lecythi\n",
            "leges\n",
            "lei\n",
            "lemmata\n",
            "lemnisci\n",
            "lenes\n",
            "lentigines\n",
            "leonides\n",
            "lepidoptera\n",
            "leprosaria\n",
            "lepta\n",
            "leptocephali\n",
            "leucocytozoa\n",
            "leva\n",
            "librae\n",
            "libretti\n",
            "lice\n",
            "lieder\n",
            "ligulae\n",
            "limbi\n",
            "limina\n",
            "limites\n",
            "limuli\n",
            "lingoes\n",
            "linguae\n",
            "linguae_francae\n",
            "lionfishes\n",
            "lipomata\n",
            "lire\n",
            "liriodendra\n",
            "listente\n",
            "litai\n",
            "litu\n",
            "lives\n",
            "lixivia\n",
            "loaves\n",
            "loci\n",
            "loculi\n",
            "loggie\n",
            "logia\n",
            "lomenta\n",
            "longobardi\n",
            "loricae\n",
            "luba\n",
            "lubritoria\n",
            "lumbus\n",
            "lumina\n",
            "lumpfishes\n",
            "lungfishes\n",
            "lunulae\n",
            "lures\n",
            "lustra\n",
            "lyings-in\n",
            "lymphangitides\n",
            "lymphomata\n",
            "lymphopoieses\n",
            "lyses\n",
            "lyttae\n",
            "maare\n",
            "macaronies\n",
            "maccaronies\n",
            "machzorim\n",
            "macronuclei\n",
            "macrosporangia\n",
            "maculae\n",
            "madornos\n",
            "maestri\n",
            "mafiosi\n",
            "magi\n",
            "magmata\n",
            "magnificoes\n",
            "mahzorim\n",
            "major-axes\n",
            "major_axes\n",
            "makuta\n",
            "mallei\n",
            "malleoli\n",
            "maloti\n",
            "mamillae\n",
            "mammae\n",
            "mammillae\n",
            "mandingoes\n",
            "mangoes\n",
            "manifestoes\n",
            "manteaux\n",
            "mantes\n",
            "manubria\n",
            "marchese\n",
            "marchesi\n",
            "maremme\n",
            "markkaa\n",
            "marsupia\n",
            "marvels-of-peru\n",
            "mass_media\n",
            "masses\n",
            "masters-at-arms\n",
            "matrices\n",
            "matzoth\n",
            "mausolea\n",
            "maxillae\n",
            "maxima\n",
            "media\n",
            "mediae\n",
            "mediastina\n",
            "medullae\n",
            "medullae_oblongatae\n",
            "medusae\n",
            "megara\n",
            "megasporangia\n",
            "megilloth\n",
            "meioses\n",
            "melanomata\n",
            "melismata\n",
            "mementoes\n",
            "memoranda\n",
            "men\n",
            "men-at-arms\n",
            "men-o'-war\n",
            "men-of-war\n",
            "men_of_letters\n",
            "menisci\n",
            "menservants\n",
            "menstrua\n",
            "mesdames\n",
            "mesdemoiselles\n",
            "mesentera\n",
            "mesothoraces\n",
            "messeigneurs\n",
            "messieurs\n",
            "mestizoes\n",
            "metacarpi\n",
            "metamorphoses\n",
            "metanephroi\n",
            "metastases\n",
            "metatarsi\n",
            "metatheses\n",
            "metathoraces\n",
            "metazoa\n",
            "metempsychoses\n",
            "metencephala\n",
            "mezuzoth\n",
            "miasmata\n",
            "mice\n",
            "microanalyses\n",
            "micrococci\n",
            "micronuclei\n",
            "microsporangia\n",
            "midrashim\n",
            "midwives\n",
            "milia\n",
            "milieux\n",
            "militated_against\n",
            "milkfishes\n",
            "millennia\n",
            "minae\n",
            "minima\n",
            "ministeria\n",
            "minutiae\n",
            "minyanim\n",
            "mioses\n",
            "miracidia\n",
            "miri\n",
            "mishnayoth\n",
            "mitochondria\n",
            "mitzvoth\n",
            "modioli\n",
            "moduli\n",
            "momenta\n",
            "moments_of_truth\n",
            "momi\n",
            "monades\n",
            "monkfishes\n",
            "monochasia\n",
            "monopodia\n",
            "monoptera\n",
            "monopteroi\n",
            "monsignori\n",
            "monts-de-piete\n",
            "mooncalves\n",
            "moonfishes\n",
            "morae\n",
            "moratoria\n",
            "morceaux\n",
            "morescoes\n",
            "moriscoes\n",
            "morphallaxes\n",
            "morphoses\n",
            "morulae\n",
            "mosasauri\n",
            "moshavim\n",
            "moslim\n",
            "moslims\n",
            "mosquitoes\n",
            "mothers-in-law\n",
            "mothers_superior\n",
            "mottoes\n",
            "movers_and_shakers\n",
            "mucosae\n",
            "mucrones\n",
            "mudejares\n",
            "mudfishes\n",
            "mulattoes\n",
            "multiparae\n",
            "murices\n",
            "muskallunge\n",
            "mycelia\n",
            "mycetomata\n",
            "mycobacteria\n",
            "mycorrhizae\n",
            "myelencephala\n",
            "myiases\n",
            "myocardia\n",
            "myofibrillae\n",
            "myomata\n",
            "myoses\n",
            "myrmidones\n",
            "mythoi\n",
            "myxomata\n",
            "naevi\n",
            "naiades\n",
            "naoi\n",
            "narcissi\n",
            "nares\n",
            "nasopharynges\n",
            "natatoria\n",
            "naumachiae\n",
            "nauplii\n",
            "nautili\n",
            "navahoes\n",
            "navajoes\n",
            "nebulae\n",
            "necropoleis\n",
            "needlefishes\n",
            "negrilloes\n",
            "negritoes\n",
            "negroes\n",
            "nemeses\n",
            "nephridia\n",
            "nereides\n",
            "neurohypophyses\n",
            "neuromata\n",
            "neuroptera\n",
            "neuroses\n",
            "nevi\n",
            "nibelungen\n",
            "nidi\n",
            "nielli\n",
            "nilgai\n",
            "nimbi\n",
            "nimbostrati\n",
            "noctilucae\n",
            "nodi\n",
            "noes\n",
            "nomina\n",
            "nota\n",
            "noumena\n",
            "novae\n",
            "novelle\n",
            "novenae\n",
            "nubeculae\n",
            "nucelli\n",
            "nuchae\n",
            "nuclei\n",
            "nucleoli\n",
            "nulliparae\n",
            "numbfishes\n",
            "numina\n",
            "nymphae\n",
            "oarfishes\n",
            "oases\n",
            "obeli\n",
            "objets_d'art\n",
            "obligati\n",
            "oboli\n",
            "occipita\n",
            "oceanaria\n",
            "oceanides\n",
            "ocelli\n",
            "ochreae\n",
            "ocreae\n",
            "octahedra\n",
            "octopi\n",
            "oculi\n",
            "odea\n",
            "oedemata\n",
            "oesophagi\n",
            "oldwives\n",
            "olea\n",
            "omasa\n",
            "omayyades\n",
            "omenta\n",
            "ommatidia\n",
            "ommiades\n",
            "onagri\n",
            "oogonia\n",
            "oothecae\n",
            "operas_seria\n",
            "opercula\n",
            "optima\n",
            "ora\n",
            "organa\n",
            "organums\n",
            "orthoptera\n",
            "osar\n",
            "oscula\n",
            "ossa\n",
            "osteomata\n",
            "ostia\n",
            "ottomans\n",
            "ova\n",
            "ovoli\n",
            "ovotestes\n",
            "oxen\n",
            "oxymora\n",
            "paddlefishes\n",
            "paise\n",
            "paleae\n",
            "palestrae\n",
            "palingeneses\n",
            "pallia\n",
            "palmettoes\n",
            "palpi\n",
            "pancratia\n",
            "panettoni\n",
            "paparazzi\n",
            "paperknives\n",
            "papillae\n",
            "papillomata\n",
            "pappi\n",
            "papulae\n",
            "papyri\n",
            "parabases\n",
            "paraleipses\n",
            "paralyses\n",
            "paramecia\n",
            "paramenta\n",
            "paraphyses\n",
            "parapodia\n",
            "parapraxes\n",
            "paraselenae\n",
            "parashoth\n",
            "parasyntheta\n",
            "parazoa\n",
            "parentheses\n",
            "parerga\n",
            "parhelia\n",
            "parietes\n",
            "paris-mutuels\n",
            "parrotfishes\n",
            "parulides\n",
            "pasos_dobles\n",
            "passers-by\n",
            "pastorali\n",
            "patagia\n",
            "patellae\n",
            "patinae\n",
            "patresfamilias\n",
            "pease\n",
            "peccadilloes\n",
            "pectines\n",
            "pedaloes\n",
            "pedes\n",
            "pekingese\n",
            "pelves\n",
            "pence\n",
            "penes\n",
            "penetralium\n",
            "penicillia\n",
            "penknives\n",
            "pennae\n",
            "pennia\n",
            "pentahedra\n",
            "pentimenti\n",
            "penumbrae\n",
            "pepla\n",
            "pericardia\n",
            "perichondria\n",
            "pericrania\n",
            "peridia\n",
            "perigonia\n",
            "perihelia\n",
            "perinea\n",
            "perinephria\n",
            "perionychia\n",
            "periostea\n",
            "periphrases\n",
            "peristalses\n",
            "perithecia\n",
            "peritonea\n",
            "personae\n",
            "petechiae\n",
            "pfennige\n",
            "phalanges\n",
            "phalli\n",
            "pharynges\n",
            "phenomena\n",
            "phi-phenomena\n",
            "philodendra\n",
            "phlyctenae\n",
            "phyla\n",
            "phylae\n",
            "phyllotaxes\n",
            "phylloxerae\n",
            "phylogeneses\n",
            "pieds-a-terre\n",
            "pigfishes\n",
            "pilea\n",
            "pilei\n",
            "pineta\n",
            "pinfishes\n",
            "pinkoes\n",
            "pinnae\n",
            "pinnulae\n",
            "pipefishes\n",
            "pirogi\n",
            "piscinae\n",
            "pithecanthropi\n",
            "pithoi\n",
            "placeboes\n",
            "placentae\n",
            "planetaria\n",
            "planulae\n",
            "plasmodesmata\n",
            "plasmodia\n",
            "plateaux\n",
            "plectra\n",
            "plena\n",
            "pleura\n",
            "pleurae\n",
            "plicae\n",
            "ploughmen\n",
            "pneumobacilli\n",
            "pneumococci\n",
            "pocketknives\n",
            "podetia\n",
            "podia\n",
            "poleis\n",
            "pollices\n",
            "pollinia\n",
            "polychasia\n",
            "polyhedra\n",
            "polyparia\n",
            "polypi\n",
            "polyzoa\n",
            "polyzoaria\n",
            "pontes\n",
            "pontifices\n",
            "portamenti\n",
            "porticoes\n",
            "portmanteaux\n",
            "postliminia\n",
            "potatoes\n",
            "praenomina\n",
            "praxes\n",
            "predelle\n",
            "premaxillae\n",
            "prenomina\n",
            "prese\n",
            "primi\n",
            "primigravidae\n",
            "primiparae\n",
            "primordia\n",
            "principia\n",
            "proboscides\n",
            "proces-verbaux\n",
            "proglottides\n",
            "prognoses\n",
            "prolegomena\n",
            "prolepses\n",
            "promycelia\n",
            "pronephra\n",
            "pronephroi\n",
            "pronuclei\n",
            "propositi\n",
            "proptoses\n",
            "propyla\n",
            "propylaea\n",
            "proscenia\n",
            "prosencephala\n",
            "prostheses\n",
            "prostomia\n",
            "protases\n",
            "prothalamia\n",
            "prothalli\n",
            "prothallia\n",
            "prothoraces\n",
            "protonemata\n",
            "protozoa\n",
            "proventriculi\n",
            "provisoes\n",
            "prytanea\n",
            "psalteria\n",
            "pseudopodia\n",
            "psychoneuroses\n",
            "psychoses\n",
            "pterygia\n",
            "pterylae\n",
            "ptoses\n",
            "pubes\n",
            "pudenda\n",
            "puli\n",
            "pulvilli\n",
            "pulvini\n",
            "punchinelloes\n",
            "pupae\n",
            "puparia\n",
            "putamina\n",
            "putti\n",
            "pycnidia\n",
            "pygidia\n",
            "pylori\n",
            "pyxides\n",
            "pyxidia\n",
            "qaddishim\n",
            "quadrennia\n",
            "quadrigae\n",
            "qualia\n",
            "quanta\n",
            "quarterstaves\n",
            "quezales\n",
            "quinquennia\n",
            "quizzes\n",
            "rabatos\n",
            "rabbitfishes\n",
            "rachides\n",
            "radices\n",
            "radii\n",
            "radulae\n",
            "ramenta\n",
            "rami\n",
            "ranulae\n",
            "ranunculi\n",
            "raphae\n",
            "raphides\n",
            "ratfishes\n",
            "reales\n",
            "rearmice\n",
            "recta\n",
            "recti\n",
            "rectrices\n",
            "redfishes\n",
            "rediae\n",
            "referenda\n",
            "refugia\n",
            "reguli\n",
            "reis\n",
            "relata\n",
            "remiges\n",
            "reremice\n",
            "reseaux\n",
            "residua\n",
            "responsa\n",
            "retia\n",
            "retiarii\n",
            "reticula\n",
            "retinacula\n",
            "retinae\n",
            "rhabdomyomata\n",
            "rhachides\n",
            "rhachises\n",
            "rhinencephala\n",
            "rhizobia\n",
            "rhombi\n",
            "rhonchi\n",
            "rhyta\n",
            "ribbonfishes\n",
            "ricercacari\n",
            "ricercari\n",
            "rickettsiae\n",
            "rilievi\n",
            "rimae\n",
            "robes-de-chambre\n",
            "rockfishes\n",
            "roma\n",
            "romans-fleuves\n",
            "rondeaux\n",
            "rosaria\n",
            "rosefishes\n",
            "rostella\n",
            "rostra\n",
            "rouleaux\n",
            "rugae\n",
            "rumina\n",
            "runners-up\n",
            "sacra\n",
            "sacraria\n",
            "saguaros\n",
            "sailfishes\n",
            "salespeople\n",
            "salmonellae\n",
            "salpae\n",
            "salpinges\n",
            "saltarelli\n",
            "salvoes\n",
            "sancta\n",
            "sanitaria\n",
            "santimi\n",
            "saphenae\n",
            "sarcophagi\n",
            "sartorii\n",
            "sassanidae\n",
            "sawfishes\n",
            "scaldfishes\n",
            "scaleni\n",
            "scapulae\n",
            "scarabaei\n",
            "scarves\n",
            "schatchonim\n",
            "schemata\n",
            "scherzandi\n",
            "scherzi\n",
            "schmoes\n",
            "scholia\n",
            "schuln\n",
            "schutzstaffeln\n",
            "scirrhi\n",
            "scleromata\n",
            "scleroses\n",
            "sclerotia\n",
            "scoleces\n",
            "scolices\n",
            "scopulae\n",
            "scoriae\n",
            "scotomata\n",
            "scriptoria\n",
            "scrota\n",
            "scudi\n",
            "scuta\n",
            "scutella\n",
            "scyphi\n",
            "scyphistomae\n",
            "scyphozoa\n",
            "secondi\n",
            "secretaries-general\n",
            "segni\n",
            "seleucidae\n",
            "selves\n",
            "senores\n",
            "sensilla\n",
            "senti\n",
            "senussis\n",
            "separatrices\n",
            "sephardim\n",
            "septa\n",
            "septaria\n",
            "septennia\n",
            "sequelae\n",
            "sequestra\n",
            "sera\n",
            "seraphim\n",
            "sestertia\n",
            "setae\n",
            "sgraffiti\n",
            "shabbasim\n",
            "shabbatim\n",
            "shackoes\n",
            "shadchanim\n",
            "shadchans\n",
            "shakoes\n",
            "shammosim\n",
            "sheatfishes\n",
            "sheaves\n",
            "shellfishes\n",
            "shelves\n",
            "shinleaves\n",
            "shittim\n",
            "shmoes\n",
            "shofroth\n",
            "shophroth\n",
            "shrewmice\n",
            "shuln\n",
            "siddurim\n",
            "sigloi\n",
            "signore\n",
            "signori\n",
            "signorine\n",
            "siliquae\n",
            "silvae\n",
            "silverfishes\n",
            "simulacra\n",
            "sincipita\n",
            "sinfonie\n",
            "sisters-in-law\n",
            "sistra\n",
            "situlae\n",
            "smalti\n",
            "snaggleteeth\n",
            "snailfishes\n",
            "snipefishes\n",
            "socmen\n",
            "sola\n",
            "solaria\n",
            "solatia\n",
            "soldi\n",
            "soles\n",
            "solfeggi\n",
            "soli\n",
            "solidi\n",
            "somata\n",
            "sons-in-law\n",
            "soprani\n",
            "sordini\n",
            "sori\n",
            "soroses\n",
            "sovkhozy\n",
            "spadefishes\n",
            "spadices\n",
            "spearfishes\n",
            "spectra\n",
            "specula\n",
            "spermatia\n",
            "spermatogonia\n",
            "spermatozoa\n",
            "spermogonia\n",
            "sphinges\n",
            "spicae\n",
            "spicula\n",
            "spirilla\n",
            "splayfeet\n",
            "splenii\n",
            "sporangia\n",
            "sporogonia\n",
            "sporozoa\n",
            "springhase\n",
            "spumoni\n",
            "sputa\n",
            "squamae\n",
            "squashes\n",
            "squillae\n",
            "squirrelfishes\n",
            "squizzes\n",
            "stadia\n",
            "stamina\n",
            "staminodia\n",
            "stapedes\n",
            "staphylococci\n",
            "starfishes\n",
            "startsy\n",
            "stelae\n",
            "stemmata\n",
            "stenoses\n",
            "stepchildren\n",
            "sterna\n",
            "stigmata\n",
            "stimuli\n",
            "stipites\n",
            "stirpes\n",
            "stoae\n",
            "stockfishes\n",
            "stomata\n",
            "stomodaea\n",
            "stomodea\n",
            "stonefishes\n",
            "stotinki\n",
            "stotkini\n",
            "strappadoes\n",
            "strata\n",
            "strati\n",
            "stratocumuli\n",
            "street_children\n",
            "streptococci\n",
            "stretti\n",
            "striae\n",
            "strobili\n",
            "stromata\n",
            "strumae\n",
            "stuccoes\n",
            "styli\n",
            "stylopes\n",
            "stylopodia\n",
            "subcortices\n",
            "subdeliria\n",
            "subgenera\n",
            "subindices\n",
            "submucosae\n",
            "subphyla\n",
            "substrasta\n",
            "succedanea\n",
            "succubi\n",
            "suckerfishes\n",
            "suckfishes\n",
            "sudaria\n",
            "sudatoria\n",
            "sulci\n",
            "summae\n",
            "sunfishes\n",
            "supercargoes\n",
            "superheroes\n",
            "supernovae\n",
            "superstrata\n",
            "surgeonfishes\n",
            "swamies\n",
            "sweetiewives\n",
            "swellfishes\n",
            "swordfishes\n",
            "syconia\n",
            "syllabi\n",
            "syllepses\n",
            "symphyses\n",
            "sympodia\n",
            "symposia\n",
            "synapses\n",
            "synarthroses\n",
            "synclinoria\n",
            "syncytia\n",
            "syndesmoses\n",
            "synopses\n",
            "syntagmata\n",
            "syntheses\n",
            "syphilomata\n",
            "syringes\n",
            "syssarcoses\n",
            "tableaux\n",
            "taeniae\n",
            "tali\n",
            "tallaisim\n",
            "tallithes\n",
            "tallitoth\n",
            "tapeta\n",
            "tarantulae\n",
            "tarsi\n",
            "tarsometatarsi\n",
            "taxa\n",
            "taxes\n",
            "taxies\n",
            "tectrices\n",
            "teeth\n",
            "tegmina\n",
            "telae\n",
            "telamones\n",
            "telangiectases\n",
            "telia\n",
            "tempi\n",
            "tenacula\n",
            "tenderfeet\n",
            "teniae\n",
            "tenues\n",
            "teraphim\n",
            "terata\n",
            "teredines\n",
            "terga\n",
            "termini\n",
            "terraria\n",
            "terzetti\n",
            "tesserae\n",
            "testae\n",
            "testes\n",
            "testudines\n",
            "tetrahedra\n",
            "tetraskelia\n",
            "thalamencephala\n",
            "thalami\n",
            "thalli\n",
            "theatres-in-the-round\n",
            "thecae\n",
            "therses\n",
            "thesauri\n",
            "theses\n",
            "thickleaves\n",
            "thieves\n",
            "tholoi\n",
            "thoraces\n",
            "thrombi\n",
            "thymi\n",
            "thyrsi\n",
            "tibiae\n",
            "tilefishes\n",
            "tintinnabula\n",
            "titmice\n",
            "toadfishes\n",
            "tobaccoes\n",
            "tomatoes\n",
            "tomenta\n",
            "tondi\n",
            "tonneaux\n",
            "tophi\n",
            "topoi\n",
            "tori\n",
            "tornadoes\n",
            "torpedoes\n",
            "torsi\n",
            "touracos\n",
            "trabeculae\n",
            "tracheae\n",
            "traditores\n",
            "tragi\n",
            "trapezia\n",
            "trapezohedra\n",
            "traumata\n",
            "treponemata\n",
            "trichinae\n",
            "triclinia\n",
            "triennia\n",
            "triforia\n",
            "triggerfishes\n",
            "trihedra\n",
            "triskelia\n",
            "trisoctahedra\n",
            "triumviri\n",
            "trivia\n",
            "trochleae\n",
            "tropaeola\n",
            "trous-de-loup\n",
            "trousseaux\n",
            "trunkfishes\n",
            "trymata\n",
            "tubae\n",
            "turves\n",
            "tympana\n",
            "tyros\n",
            "ubermenschen\n",
            "uglies\n",
            "uigurs\n",
            "ulnae\n",
            "ultimata\n",
            "umbilici\n",
            "umbones\n",
            "umbrae\n",
            "unci\n",
            "uncidia\n",
            "uredines\n",
            "uredinia\n",
            "uredosori\n",
            "urethrae\n",
            "urinalyses\n",
            "uteri\n",
            "utriculi\n",
            "uvulae\n",
            "vacua\n",
            "vagi\n",
            "vaginae\n",
            "valleculae\n",
            "vaporetti\n",
            "varices\n",
            "vasa\n",
            "vascula\n",
            "vela\n",
            "velamina\n",
            "velaria\n",
            "venae\n",
            "venae_cavae\n",
            "ventriculi\n",
            "vermes\n",
            "verrucae\n",
            "vertebrae\n",
            "vertices\n",
            "vertigines\n",
            "vertigoes\n",
            "vesicae\n",
            "vetoes\n",
            "vexilla\n",
            "viatica\n",
            "viatores\n",
            "vibracula\n",
            "vibrissae\n",
            "vice-chairman\n",
            "villi\n",
            "vimina\n",
            "vincula\n",
            "viragoes\n",
            "vires\n",
            "virtuosi\n",
            "vitae\n",
            "vitelli\n",
            "vittae\n",
            "vivaria\n",
            "voces\n",
            "volcanoes\n",
            "volkslieder\n",
            "volte\n",
            "volvae\n",
            "vorticellae\n",
            "vortices\n",
            "vulvae\n",
            "wagons-lits\n",
            "wahhabis\n",
            "wanderjahre\n",
            "weakfishes\n",
            "werewolves\n",
            "wharves\n",
            "whippers-in\n",
            "whitefishes\n",
            "wives\n",
            "wolffishes\n",
            "wolves\n",
            "woodlice\n",
            "wreckfishes\n",
            "wunderkinder\n",
            "xiphisterna\n",
            "yeshivahs\n",
            "yeshivoth\n",
            "yogin\n",
            "yourselves\n",
            "zamindaris\n",
            "zecchini\n",
            "zeroes\n",
            "zoa\n",
            "zoaeae\n",
            "zoeae\n",
            "zoeas\n",
            "zoonoses\n",
            "zoosporangia\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorboardX"
      ],
      "metadata": {
        "id": "ZUck_ephe-_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TClLhWKJe8bH",
        "outputId": "0f75c829-ba33-4daf-daab-9fef31ca9d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "WpRXxZ9FDA6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNvBUaT9C_uq",
        "outputId": "53efeb5b-f203-42f9-eb06-62727764c241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy Source Codes"
      ],
      "metadata": {
        "id": "3I-bWS4Rt0js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/colab/ExSum/SRC ."
      ],
      "metadata": {
        "id": "ETV5eDl999k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "2bokL3LKqKP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import easydict"
      ],
      "metadata": {
        "id": "xxzCS-_8tNa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing  "
      ],
      "metadata": {
        "id": "91x3wJjFs057"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. 데이터 다운로드\n",
        "- AI Hub 문서요약 텍스트 데이터 (https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=97)\n",
        "- 데이터셋 사용 신청 후 다운로드 가능 (신청하는 즉시 승인 완료됨)\n",
        "  - Training / Validation 폴더 있음\n",
        "  - 법률, 사설, 신문기사 별로 train_original.json / valid_original.json 파일이 압축되어 있음\n",
        "- DATA 폴더 생성 후 업로드\n",
        "  - raw_data/train, raw_data/valid 하위 폴더 생성\n",
        "  - 법률, 사설, 신문기사를 각각 law, opinion, news로 저장."
      ],
      "metadata": {
        "id": "MTHuiNGNCPSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 원본 데이터 탐색 및 가공"
      ],
      "metadata": {
        "id": "uenosJWyr1H_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2-1. 원본 데이터 탐색\n",
        "- 데이터 구성\n",
        "  - 원문 데이터 40만 건 (신문기사 30만 건, 기고문 6만 건, 잡지기사 1만 건, 법원 판결문 3만 건)을 활용하여 각각 추출요약 40만 건, 생성요약 40만 건, 총 80만 건의 요약문 도출\n",
        "  - 원문으로부터 변형 없이 그대로 선택된 3개 문장으로 추출요약문 생성\n",
        "  - 원문의 내용을 바탕으로 재작성된 생성요약문 생성"
      ],
      "metadata": {
        "id": "4TXXmh2ECSmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3JL8_2IQucxt",
        "outputId": "6a65b7a9-3b8b-4751-b820-4ff58d761939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = \"./drive/MyDrive/colab/ExSum/DATA/raw_data/train\"\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2IMRrqa-ZYl",
        "outputId": "65adbd84-0033-4037-8e67-8a2da63e4a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_original_law.json',\n",
              " 'train_original_news.json',\n",
              " 'train_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = filenames[0]\n",
        "filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "with open(filelocation, 'r') as json_file:\n",
        "  data = json.load(json_file)['documents']"
      ],
      "metadata": {
        "id": "S8FxkBHwABM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5nstQNiA-eS",
        "outputId": "7884afc0-957a-421d-ebba-a1d112f2e87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '100004',\n",
              " 'category': '일반행정',\n",
              " 'size': 'small',\n",
              " 'char_count': 377,\n",
              " 'publish_date': '19841226',\n",
              " 'title': '부당노동행위구제재심판정취소',\n",
              " 'text': [[{'index': 0,\n",
              "    'sentence': '원고가 소속회사의 노동조합에서 분규가 발생하자 노조활동을 구실로 정상적인 근무를 해태하고,',\n",
              "    'highlight_indices': ''},\n",
              "   {'index': 1, 'sentence': '노조조합장이 사임한 경우,', 'highlight_indices': ''},\n",
              "   {'index': 2,\n",
              "    'sentence': '노동조합규약에 동 조합장의 직무를 대행할 자를 규정해 두고 있음에도 원고 자신이 주동하여 노조자치수습대책위원회를 구성하여 그 위원장으로 피선되어 근무시간중에도 노조활동을 벌여 운수업체인 소속회사의 업무에 지장을 초래하고',\n",
              "    'highlight_indices': '8,9;68,69'},\n",
              "   {'index': 3,\n",
              "    'sentence': '종업원들에게도 나쁜 영향을 끼쳐 소속회사가 취업규칙을 위반하고',\n",
              "    'highlight_indices': ''},\n",
              "   {'index': 4,\n",
              "    'sentence': '고의로 회사업무능률을 저해하였으며 회사업무상의 지휘명령에 위반하였음을 이유로 원고를 징계해고 하였다면,',\n",
              "    'highlight_indices': '0,3'},\n",
              "   {'index': 5,\n",
              "    'sentence': '이는 원고의 노동조합 활동과는 관계없이 회사취업규칙에 의하여 사내질서를 유지하기 위한 사용자 고유의 징계권에 기하여 이루어진 정당한 징계권의 행사로 보아야 한다.',\n",
              "    'highlight_indices': '17,21'}]],\n",
              " 'annotator_id': 3783,\n",
              " 'document_quality_scores': {'readable': 3,\n",
              "  'accurate': 3,\n",
              "  'informative': 3,\n",
              "  'trustworthy': 3},\n",
              " 'extractive': [5, 4, 2],\n",
              " 'abstractive': ['원고가  주동하여 회사업무능률을 저해하고 회사업무상의 지휘명령에 위반하였다면 이에 따른 징계해고는 사내질서를 유지하기 위한 사용자 고유의 정당한 징계권의 행사로 보아야 한다.']}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2.원본 데이터에서 필요한 값 추출\n",
        "- 'text'와 'extractive' 추출\n",
        "  - 'text': 정규식을 이용해서 sentence - highlight_indices 사이의 문장 추출한 후 리스트로 저장\n",
        "  - 'extractive': 3줄 요약에 해당하는 문장 index 3개가 저장된 리스트\n",
        "- 신문기사, 기고문, 법원 판결문 3개로 나누어져 있는 파일을 하나로 합침\n",
        "  - train, valid 각각에 대해 수행"
      ],
      "metadata": {
        "id": "Cr4ZKm5ZEHm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 데이터"
      ],
      "metadata": {
        "id": "_zZ-flhQ2yks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = \"./drive/MyDrive/colab/ExSum/DATA/raw_data/train\"\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "id": "qD3S1a3p2bR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3be3a3-521f-4260-ae4f-2bf717d4183a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_original_law.json',\n",
              " 'train_original_news.json',\n",
              " 'train_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_dic = []\n",
        "\n",
        "for file in filenames:\n",
        "  filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "  with open(filelocation, 'r') as json_file:\n",
        "    data = json.load(json_file)['documents']\n",
        "\n",
        "    for x in tqdm (range(len(data))):\n",
        "      text = data[x]['text']\n",
        "      text = str(text).replace('\"', \"'\")\n",
        "\n",
        "      extractive = data[x]['extractive']\n",
        "      for index, value in enumerate(extractive):\n",
        "        if value == None:\n",
        "          extractive[index] = 0\n",
        "\n",
        "      p = re.compile('(?<=sentence\\'\\: \\')(.*?)(?=\\'highlight_indices)')\n",
        "      texts = p.findall(text)\n",
        "\n",
        "      sentences = []\n",
        "      for t in texts:\n",
        "        sentence = t[:-3]\n",
        "        sentences.append(sentence)\n",
        "\n",
        "      mydict = {}\n",
        "      mydict['text'] = sentences\n",
        "      mydict['extractive'] = extractive\n",
        "      list_dic.append(mydict)"
      ],
      "metadata": {
        "id": "xCPurpAs3h_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a24492-158a-413e-c3d3-f2f6189804f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24329/24329 [00:01<00:00, 13178.53it/s]\n",
            "100%|██████████| 243983/243983 [00:28<00:00, 8488.44it/s] \n",
            "100%|██████████| 56760/56760 [00:07<00:00, 7310.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./drive/MyDrive/colab/ExSum/DATA/raw_data/train.json\", 'w') as fh:\n",
        "  json.dump(list_dic, fh)"
      ],
      "metadata": {
        "id": "cTEtVjM6AF0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Google Colab의 제한된 RAM 환경에서는 train.json 데이터를 BERT로 학습 가능한 데이터(*.pt)로 변환 시 세션이 죽는 현상 발생\n",
        "- 이에 따라 train.json 파일을 분할"
      ],
      "metadata": {
        "id": "ZX1hxXmMt25_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./drive/MyDrive/colab/ExSum/DATA/raw_data/train.json\", 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "  print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCMlKeFMt2PU",
        "outputId": "062ea062-fc56-4268-d296-40b1b390a7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "325072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_chunk(lst, n):\n",
        "    return [lst[i:i+n] for i in range(0, len(lst), n)]\n",
        "\n",
        "data_chunked = list_chunk(data, 32507) ## 전체 데이터를 10개로 분할\n",
        "\n",
        "for i, d in enumerate(data_chunked):\n",
        "  with open(\"./drive/MyDrive/colab/ExSum/DATA/raw_data/train.{}.json\".format(i), 'w') as fh:\n",
        "    json.dump(d, fh)"
      ],
      "metadata": {
        "id": "gcDGrR2Dvm3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valid 데이터"
      ],
      "metadata": {
        "id": "qq02fYAq3GT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = \"./drive/MyDrive/colab/ExSum/DATA/raw_data/valid\"\n",
        "filenames = [x for x in os.listdir (DATAPATH) if x.endswith('json')]\n",
        "filenames.sort()\n",
        "filenames"
      ],
      "metadata": {
        "id": "16DZgFsc2_mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e25225-7276-4b72-8439-d85220af2114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valid_original_law.json',\n",
              " 'valid_original_news.json',\n",
              " 'valid_original_opinion.json']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_dic = []\n",
        "\n",
        "for file in filenames:\n",
        "  filelocation = os.path.join(DATAPATH, file)\n",
        "\n",
        "  with open(filelocation, 'r') as json_file:\n",
        "    data = json.load(json_file)['documents']\n",
        "\n",
        "    for x in tqdm (range(len(data))):\n",
        "      text = data[x]['text']\n",
        "      text = str(text).replace('\"', \"'\")\n",
        "\n",
        "      extractive = data[x]['extractive']\n",
        "      for index, value in enumerate(extractive):\n",
        "        if value == None:\n",
        "          extractive[index] = 0\n",
        "\n",
        "      p = re.compile('(?<=sentence\\'\\: \\')(.*?)(?=\\'highlight_indices)')\n",
        "      texts = p.findall(text)\n",
        "\n",
        "      sentences = []\n",
        "      for t in texts:\n",
        "        sentence = t[:-3]\n",
        "        sentences.append(sentence)\n",
        "\n",
        "      mydict = {}\n",
        "      mydict['text'] = sentences\n",
        "      mydict['extractive'] = extractive\n",
        "      list_dic.append(mydict)"
      ],
      "metadata": {
        "id": "J7LP24bJ2_mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e741e9-7627-4ed2-c643-ac140686e341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3004/3004 [00:00<00:00, 13564.56it/s]\n",
            "100%|██████████| 30122/30122 [00:03<00:00, 9149.68it/s]\n",
            "100%|██████████| 7008/7008 [00:00<00:00, 9364.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./drive/MyDrive/colab/ExSum/DATA/raw_data/valid.json\", 'w') as fh:\n",
        "  json.dump(list_dic, fh)"
      ],
      "metadata": {
        "id": "xAI46oPu2_mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 학습 가능한 형태의 데이터로 변환"
      ],
      "metadata": {
        "id": "6kZFeXPG3oiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1. Tokenizing 후 .json 파일로 저장\n",
        "- Source 및 Target 설정\n",
        "  - Source; 원본 데이터의 'text'에 해당\n",
        "  - Target; 원본 데이터의 'extractive' 리스트의 index에 해당하는 문장을 source에서 추출\n",
        "- Source 및 Target 을 Tokenizing\n",
        "  - Tokenizer; MeCab + BertTokenizer\n",
        "    - 한국어 데이터이므로 MeCab으로 형태소 분석 후 BertTokenizer 사용\n",
        "  - Tokenizing 후 token 단위로 source 및 target 저장"
      ],
      "metadata": {
        "id": "Z0zYmtV_CbWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "HjDNwRK_sXQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train 데이터"
      ],
      "metadata": {
        "id": "YDOHhXZKSy8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = \"./drive/MyDrive/colab/ExSum/DATA/raw_data/\"\n",
        "filenames = [x for x in os.listdir (DATAPATH) if 'train' in x and x.endswith('json')]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBlT2mhgxhAL",
        "outputId": "2e72bc59-9a69-4dc5-bc55-98959a582a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.json',\n",
              " 'train.1.json',\n",
              " 'train.2.json',\n",
              " 'train.3.json',\n",
              " 'train.4.json',\n",
              " 'train.5.json',\n",
              " 'train.0.json',\n",
              " 'train.6.json',\n",
              " 'train.7.json',\n",
              " 'train.8.json',\n",
              " 'train.9.json',\n",
              " 'train.10.json']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainfiles = []\n",
        "for f in filenames[1:-1]:\n",
        "  trainfiles.append(f[:-5])"
      ],
      "metadata": {
        "id": "dHvbjSIiyRmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for set_name in trainfiles:\n",
        "  print(\"Processing ... \", set_name)\n",
        "\n",
        "  with open(\"./drive/MyDrive/colab/ExSum/DATA/raw_data/{}.json\".format(set_name), 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "    list_dic = []\n",
        "    for x in tqdm(range(len(data))):\n",
        "      text = data[x]['text']\n",
        "      extractive = data[x]['extractive']\n",
        "\n",
        "      sentences = []\n",
        "      for sentence in text:\n",
        "        sentence_morph = ' '.join(mecab.morphs(sentence))\n",
        "        sentences.append(sentence_morph)\n",
        "\n",
        "      extractives = []\n",
        "      for e in extractive:\n",
        "        extractives.append(sentences[e])\n",
        "\n",
        "      src = [i.split(' ') for i in sentences]\n",
        "      tgt = [i.split(' ') for i in extractives]\n",
        "\n",
        "      mydict = {}\n",
        "      mydict['src'] = src\n",
        "      mydict['tgt'] = tgt\n",
        "      list_dic.append(mydict)\n",
        "\n",
        "    jsonfilelocation = './drive/MyDrive/colab/ExSum/DATA/json_data/' + 'train'\n",
        "    os.makedirs(jsonfilelocation, exist_ok=True)\n",
        "\n",
        "    temp = []\n",
        "    DATA_PER_FILE = 50\n",
        "\n",
        "    for i,a in enumerate(tqdm(list_dic)):\n",
        "      if (i+1)%DATA_PER_FILE!=0:\n",
        "        temp.append(a)\n",
        "      else:\n",
        "        temp.append(a)\n",
        "        filename = 'korean.'+ set_name + '.' + str(i//DATA_PER_FILE)+'.json'\n",
        "        with open(os.path.join(jsonfilelocation, filename), \"w\", encoding='utf-8') as json_file:\n",
        "          json.dump(temp, json_file, ensure_ascii=False)\n",
        "          temp = []\n",
        "\n",
        "      #마지막에 남은 데이터 있으면 추가로 append\n",
        "      if len(temp) != 0:\n",
        "        filename = 'korean.'+ set_name + '.' + str(i//DATA_PER_FILE + 1)+'.json'\n",
        "        with open(os.path.join(jsonfilelocation, filename), \"w\", encoding='utf-8') as json_file:\n",
        "          json.dump(temp, json_file, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "RmtRVjBWS0sp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda128cc-e8ca-46f2-adcd-3edb86b1ccfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:00<00:00, 534.14it/s]\n",
            "100%|██████████| 32507/32507 [07:29<00:00, 72.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:14<00:00, 436.24it/s]\n",
            "100%|██████████| 32507/32507 [08:29<00:00, 63.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:12<00:00, 449.19it/s]\n",
            "100%|██████████| 32507/32507 [08:31<00:00, 63.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:12<00:00, 448.90it/s]\n",
            "100%|██████████| 32507/32507 [08:24<00:00, 64.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:11<00:00, 454.68it/s]\n",
            "100%|██████████| 32507/32507 [08:12<00:00, 65.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:12<00:00, 449.46it/s]\n",
            "100%|██████████| 32507/32507 [08:21<00:00, 64.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:12<00:00, 445.63it/s]\n",
            "100%|██████████| 32507/32507 [08:22<00:00, 64.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:09<00:00, 469.24it/s]\n",
            "100%|██████████| 32507/32507 [08:11<00:00, 66.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:24<00:00, 384.57it/s]\n",
            "100%|██████████| 32507/32507 [08:58<00:00, 60.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ...  train9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32507/32507 [01:29<00:00, 364.80it/s]\n",
            "100%|██████████| 32507/32507 [08:48<00:00, 61.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Valid 데이터"
      ],
      "metadata": {
        "id": "XBI9o0X4Sw3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_name = 'valid'\n",
        "\n",
        "with open(\"./drive/MyDrive/colab/ExSum/DATA/raw_data/{}.json\".format(set_name), 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "  list_dic = []\n",
        "  for x in tqdm(range(len(data))):\n",
        "    text = data[x]['text']\n",
        "    extractive = data[x]['extractive']\n",
        "\n",
        "    sentences = []\n",
        "    for sentence in text:\n",
        "      sentence_morph = ' '.join(mecab.morphs(sentence))\n",
        "      sentences.append(sentence_morph)\n",
        "\n",
        "    extractives = []\n",
        "    for e in extractive:\n",
        "      extractives.append(sentences[e])\n",
        "\n",
        "    src = [i.split(' ') for i in sentences]\n",
        "    tgt = [i.split(' ') for i in extractives]\n",
        "\n",
        "    mydict = {}\n",
        "    mydict['src'] = src\n",
        "    mydict['tgt'] = tgt\n",
        "    list_dic.append(mydict)\n",
        "\n",
        "  jsonfilelocation = './drive/MyDrive/colab/ExSum/DATA/json_data/' + set_name\n",
        "  os.makedirs(jsonfilelocation, exist_ok=True)\n",
        "\n",
        "  temp = []\n",
        "  DATA_PER_FILE = 50\n",
        "\n",
        "  for i,a in enumerate(tqdm(list_dic)):\n",
        "    if (i+1)%DATA_PER_FILE!=0:\n",
        "      temp.append(a)\n",
        "    else:\n",
        "      temp.append(a)\n",
        "      filename = 'korean.'+ set_name + '.' + str(i//DATA_PER_FILE)+'.json'\n",
        "      with open(os.path.join(jsonfilelocation, filename), \"w\", encoding='utf-8') as json_file:\n",
        "        json.dump(temp, json_file, ensure_ascii=False)\n",
        "        temp = []\n",
        "\n",
        "    #마지막에 남은 데이터 있으면 추가로 append\n",
        "    if len(temp) != 0:\n",
        "      filename = 'korean.'+ set_name + '.' + str(i//DATA_PER_FILE + 1)+'.json'\n",
        "      with open(os.path.join(jsonfilelocation, filename), \"w\", encoding='utf-8') as json_file:\n",
        "        json.dump(temp, json_file, ensure_ascii=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq8qemx9SoGn",
        "outputId": "39ea02e0-8719-41a0-a3fc-643ed94eb405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40134/40134 [02:07<00:00, 315.03it/s]\n",
            "100%|██████████| 40134/40134 [13:54<00:00, 48.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2. BERT feature 생성 후 .pt 파일로 저장\n",
        "- `format_to_bert` 함수 이용\n",
        "- prepro > data_builder.py\n",
        "  - `BertData()` 클래스에서 tokenizer 설정\n",
        "  - `BertTokenizer.from_pretrained('klue/bert-base', strip_accents=False, do_lower_case=False)`"
      ],
      "metadata": {
        "id": "6tMd_QvoTnJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from os.path import join as pjoin\n",
        "\n",
        "from multiprocess import Pool\n",
        "from SRC.prepro.data_builder import _format_to_bert\n",
        "\n",
        "def format_to_bert(args):\n",
        "    if (args.dataset != ''):\n",
        "        datasets = args.dataset\n",
        "    else:\n",
        "        datasets = ['train', 'valid', 'test']\n",
        "    for corpus_type in datasets:\n",
        "        a_lst = []\n",
        "        for json_f in glob.glob(pjoin(args.raw_path, corpus_type, '*' + corpus_type + '.*.json')):\n",
        "            real_name = json_f.split('/')[-1]\n",
        "            a_lst.append((json_f, args, pjoin(args.save_path, real_name.replace('json', 'bert.pt'))))\n",
        "        # print(a_lst)\n",
        "        pool = Pool(args.n_cpus)\n",
        "        for d in pool.imap(_format_to_bert, a_lst):\n",
        "            pass\n",
        "\n",
        "        pool.close()\n",
        "        pool.join()"
      ],
      "metadata": {
        "id": "es5L_1Sg0LDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train 데이터"
      ],
      "metadata": {
        "id": "dLLchXycuipd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_name = 'train'\n",
        "\n",
        "bertfilelocation = './drive/MyDrive/colab/ExSum/DATA/bert_data/' + set_name\n",
        "os.makedirs(bertfilelocation, exist_ok=True)\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "  \"dataset\": [set_name], \n",
        "  \"raw_path\": \"./drive/MyDrive/colab/ExSum/DATA/json_data/\",\n",
        "  \"save_path\": bertfilelocation,\n",
        "  \"n_cpus\":4,\n",
        "  \"oracle_mode\": \"greedy\",\n",
        "  \"min_src_ntokens\": 5,\n",
        "  \"max_src_ntokens\": 200,\n",
        "  \"min_nsents\": 3,\n",
        "  \"max_nsents\": 100,\n",
        "})\n",
        "\n",
        "format_to_bert(args)"
      ],
      "metadata": {
        "id": "-a-CFCJ3uipd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Valid 데이터"
      ],
      "metadata": {
        "id": "Yk26oSnQudU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_name = 'valid'\n",
        "\n",
        "bertfilelocation = './drive/MyDrive/colab/ExSum/DATA/bert_data/' + set_name\n",
        "os.makedirs(bertfilelocation, exist_ok=True)\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "  \"dataset\": [set_name], \n",
        "  \"raw_path\": \"./drive/MyDrive/colab/ExSum/DATA/json_data/\",\n",
        "  \"save_path\": bertfilelocation,\n",
        "  \"n_cpus\":4,\n",
        "  \"oracle_mode\": \"greedy\",\n",
        "  \"min_src_ntokens\": 5,\n",
        "  \"max_src_ntokens\": 200,\n",
        "  \"min_nsents\": 3,\n",
        "  \"max_nsents\": 100,\n",
        "})\n",
        "\n",
        "format_to_bert(args)"
      ],
      "metadata": {
        "id": "Xl6e0EeiVR_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "Mfvyw1OY35cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 사전 학습 모델 로딩\n",
        "- models > model_builder.py\n",
        "  - `Bert()` 클래스에서 model 설정\n",
        "  - `BertModel.from_pretrained('klue/bert-base')`\n",
        "- train.py\n",
        "  - `validate`와 `test` 함수에서 config 설정\n",
        "  - `BertConfig.from_pretrained('klue/bert-base')`"
      ],
      "metadata": {
        "id": "_nVsZHvP3_Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. 인코더 설정\n",
        "- models > encoder.py\n",
        "  - `Classifier()` 클래스\n",
        "  - `TransformerInterEncoder()` 클래스\n",
        "  - `RNNEncoder()` 클래스\n",
        "- models > model_builder.py\n",
        "  - `Summarizer()` 클래스에서 encoder 설정"
      ],
      "metadata": {
        "id": "kNJOLuCa96Bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "5ATF4hkLI19w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 학습 loss 함수 설정\n",
        "- models > trainer.py\n",
        "  - `__init__` 함수에서 loss 설정\n",
        "  - `torch.nn.BCELoss(reduction='none')`"
      ],
      "metadata": {
        "id": "NPdUHEZRKyW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 하이퍼파라미터 설정\n",
        "- 경로 관련 하이퍼파라미터\n",
        "  - model_path (Path): Fine-tuning한 모델이 저장되는 경로\n",
        "  - result_path (Path): 평가 시 추론 결과(candidate)와 정답(gold)이 저장되는 경로\n",
        "  - temp_dir (Path): 평가 시 ROUGE SCORE 결과가 저장되는 경로\n",
        "  - log_file (Path): 로그 파일이 저장되는 경로\n",
        "  - train_from (Path): 학습하고자 하는 체크포인트(pt)가 있을 경우 설정하는 경로\n",
        "  - bert_data_path (Path): 학습에 사용할 Bert Data(.pt)를 설정하는 경로\n",
        "\n",
        "- 모델 관련 하이퍼파라미터\n",
        "  - batch_size (int): A Batch Size (default=1000)\n",
        "  - use_interval (bool): 학습 시 문서 내에서 여러 문장을 구별하기 위해 Interval Segment Embeddings를 사용하는 지의 여부 (default=True)\n",
        "  - hidden_size (int): Transformer Hidden Size (default=128)\n",
        "  - ff_size (int): Feed-forward Filter Size (default=2048)\n",
        "  - heads (int): Transformer Head 개수 (default=8)\n",
        "  - inter_layers (int): Transformer Inter Layer 개수 (default=2)\n",
        "  - rnn_size (int): Encoder RNN RNN Size(default=512)\n",
        "  - train_steps(int): 학습할 Step 수\n",
        "\n",
        "- Optimizer 관련 하이퍼파라미터\n",
        "  - param_init (float): (default=0)\n",
        "  - param_init_glorot (bool): (default=True)\n",
        "  - dropout (float): Dropout (default=0.1)\n",
        "  - optim (str): Optimizer (default='adam')\n",
        "  - lr (float): Learning Rate (default=2e-3)\n",
        "  - beta1 (float): Adam Optimizer 관련 Hyper Parameter (default= 0.9)\n",
        "  - beta2 (float): Adam Optimizer 관련 Hyper Parameter (default=0.999)\n",
        "  - decay_method (str): Weight Decay (default='noam')\n",
        "  - warmup_steps (int): Warm-up Steps (default=6000)\n",
        "  - max_grad_norm (float): Max Gradient Noam (default=0)\n",
        "\n",
        "- 모델 저장 관련 하이퍼파라미터\n",
        "  - save_checkpoint steps (int): 모델 저장 주기\n",
        "\n",
        "- Multi-GPU 관련 하이퍼파라미터\n",
        "  - world_size (int): GPU 개수\n",
        "  - visible_gpus (str): GPU 번호\n",
        "  - gpu_ranks (str): GPU 번호\n",
        "  - seed (int): (default=666)\n",
        "\n",
        "- 기타 하이퍼파라미터\n",
        "  - accum_count (int): (default=2)\n",
        "  - report_every (int): (default=50)\n",
        "  - recall_eval (bool): (default=false)\n",
        "  - report_rouge (bool): (default=false)\n",
        "  - block_trigram (bool): (default=true)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4vO52TT7LBTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Multi-GPU 설정\n",
        "- train.py\n",
        "  - `multi_main` 과 `run` 함수 참조\n",
        "  - multiprocessing 중 spawn 사용\n",
        "\n",
        "```\n",
        "if(args.world_size>1):\n",
        "  multi_main(args)\n",
        "```\n",
        "- distributed.py\n",
        "  - `multi_init` 함수 참조\n",
        "  - 분산학습 사용\n",
        "- Colab 은 Multi-GPU를 지원하지 않으므로, 개인 장비에서 가능하다면 실행 추천\n"
      ],
      "metadata": {
        "id": "X-r2N5z3USrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ROUGE 설정\n",
        "- models > trainer.py\n",
        "  - `Trainer()` 클래스의 `test` 함수 참조\n",
        "- others > utils.py\n",
        "  - `test_rouge`, `rouge_results_to_str` 함수 사용"
      ],
      "metadata": {
        "id": "zURCz0COBWVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 최종 학습 코드\n",
        "- train.py에서 mode를 train으로 선택"
      ],
      "metadata": {
        "id": "v38YNoPKeMR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU 확인"
      ],
      "metadata": {
        "id": "JVrHsyDsVk60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbkDBqvuelL5",
        "outputId": "1434a8d6-227a-434a-8cba-eb1cb3018290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep  3 14:30:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-1. Classifier"
      ],
      "metadata": {
        "id": "RT6AH_ufkdTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = './drive/MyDrive/colab/ExSum/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "!python ./SRC/train.py \\\n",
        "  -mode train \\\n",
        "  -encoder classifier \\\n",
        "  -dropout 0.1 \\\n",
        "  -bert_data_path ./drive/MyDrive/colab/ExSum/DATA/KLUE/bert_data/train/korean \\\n",
        "  -model_path ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_classifier \\\n",
        "  -lr 2e-3 \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -report_every 1000\\\n",
        "  -save_checkpoint_steps 100 \\\n",
        "  -batch_size 1000 \\\n",
        "  -decay_method noam \\\n",
        "  -train_steps 1000 \\\n",
        "  -accum_count 2 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_classifier.txt \\\n",
        "  -use_interval true \\\n",
        "  -warmup_steps 200"
      ],
      "metadata": {
        "id": "6bywufMoUYgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca22f488-79ed-4b0c-bc72-e37e9b8a73bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-09-03 14:32:42,580 INFO] Device ID 0\n",
            "[2022-09-03 14:32:42,581 INFO] Device cuda\n",
            "Downloading config.json: 100% 425/425 [00:00<00:00, 476kB/s]\n",
            "Downloading pytorch_model.bin: 100% 424M/424M [00:06<00:00, 69.5MB/s]\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-09-03 14:32:55,022 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Classifier(\n",
            "    (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2022-09-03 14:32:55,268 INFO] * number of parameters: 110618113\n",
            "[2022-09-03 14:32:55,269 INFO] Start training...\n",
            "[2022-09-03 14:33:28,622 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.302.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:33:37,143 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.222.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:33:42,657 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.126.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:33:48,610 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.578.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:33:54,636 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.407.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:33:56,366 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_100.pt\n",
            "[2022-09-03 14:34:01,239 INFO] Training Loss 3.588610\n",
            "[2022-09-03 14:34:05,087 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.13.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:11,513 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.588.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:17,955 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.120.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:23,631 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.383.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:28,950 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.481.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:29,994 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_200.pt\n",
            "[2022-09-03 14:34:35,012 INFO] Training Loss 2.789989\n",
            "[2022-09-03 14:34:39,862 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.5.448.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:46,040 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.166.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:52,257 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.516.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:34:57,981 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.252.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:03,961 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_300.pt\n",
            "[2022-09-03 14:35:09,881 INFO] Training Loss 2.485449\n",
            "[2022-09-03 14:35:10,697 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.211.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:16,740 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.367.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:23,323 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.90.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:29,365 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.240.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:35,246 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.19.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:39,720 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_400.pt\n",
            "[2022-09-03 14:35:44,904 INFO] Training Loss 2.288964\n",
            "[2022-09-03 14:35:46,475 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.639.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:52,897 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.16.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:35:59,904 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.506.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:05,553 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.69.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:11,940 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.240.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:14,317 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_500.pt\n",
            "[2022-09-03 14:36:19,232 INFO] Training Loss 2.103065\n",
            "[2022-09-03 14:36:23,084 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.75.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:29,042 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.359.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:35,106 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.117.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:40,817 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.0.182.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:45,645 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.519.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:36:48,757 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_600.pt\n",
            "[2022-09-03 14:36:54,071 INFO] Training Loss 2.007150\n",
            "[2022-09-03 14:36:57,514 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.230.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:03,432 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.209.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:09,485 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.0.263.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:14,590 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.11.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:20,891 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.605.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:22,871 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_700.pt\n",
            "[2022-09-03 14:37:28,314 INFO] Training Loss 1.941180\n",
            "[2022-09-03 14:37:32,113 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.284.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:38,678 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.631.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:44,851 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.337.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:50,725 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.215.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:56,656 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.81.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:37:57,440 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_800.pt\n",
            "[2022-09-03 14:38:02,741 INFO] Training Loss 1.895006\n",
            "[2022-09-03 14:38:07,650 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.360.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:38:13,404 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.200.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:38:19,447 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.646.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:38:25,748 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.60.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:38:31,428 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.563.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:38:32,730 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_900.pt\n",
            "[2022-09-03 14:38:38,213 INFO] Training Loss 1.849311\n",
            "[2022-09-03 14:38:42,997 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.235.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:38:48,614 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.558.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:38:54,683 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.123.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:00,479 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.148.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:06,145 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.158.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:07,417 INFO] Step 1000/ 1000; xent: 1.82; lr: 0.0000632;  14 docs/s;    339 sec\n",
            "[2022-09-03 14:39:07,437 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_classifier/model_step_1000.pt\n",
            "[2022-09-03 14:39:13,259 INFO] Training Loss 0.000000\n",
            "[2022-09-03 14:39:13,636 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.67.bert.pt, number of examples: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-2. RNN"
      ],
      "metadata": {
        "id": "UPxFhZXNwi8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = './drive/MyDrive/colab/ExSum/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "!python ./SRC/train.py \\\n",
        "  -mode train \\\n",
        "  -encoder rnn \\\n",
        "  -dropout 0.1 \\\n",
        "  -bert_data_path ./drive/MyDrive/colab/ExSum/DATA/KLUE/bert_data/train/korean \\\n",
        "  -model_path ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_rnn \\\n",
        "  -lr 2e-3 \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -report_every 1000\\\n",
        "  -save_checkpoint_steps 100 \\\n",
        "  -batch_size 1000 \\\n",
        "  -decay_method noam \\\n",
        "  -train_steps 1000 \\\n",
        "  -accum_count 2 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_rnn.txt \\\n",
        "  -use_interval true \\\n",
        "  -warmup_steps 200 \\\n",
        "  -rnn_size 768"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT9yEYZKwi8f",
        "outputId": "b8630333-4c51-4ebe-d57a-dc0659c220e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-09-03 14:39:18,265 INFO] Device ID 0\n",
            "[2022-09-03 14:39:18,266 INFO] Device cuda\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-09-03 14:39:25,852 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): RNNEncoder(\n",
            "    (rnn): LayerNormLSTM(\n",
            "      (hidden0): ModuleList(\n",
            "        (0): LayerNormLSTMCell(\n",
            "          768, 384\n",
            "          (ln_ih): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_hh): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_ho): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (hidden1): ModuleList(\n",
            "        (0): LayerNormLSTMCell(\n",
            "          768, 384\n",
            "          (ln_ih): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_hh): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (ln_ho): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2022-09-03 14:39:25,969 INFO] * number of parameters: 114177025\n",
            "[2022-09-03 14:39:25,970 INFO] Start training...\n",
            "[2022-09-03 14:39:26,294 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.302.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:35,582 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.222.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:42,615 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.126.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:49,996 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.578.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:57,385 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.407.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:39:59,483 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_100.pt\n",
            "[2022-09-03 14:40:05,101 INFO] Training Loss 2.592205\n",
            "[2022-09-03 14:40:09,533 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.13.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:40:17,500 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.588.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:40:24,873 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.120.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:40:31,826 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.383.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:40:37,713 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.481.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:40:38,889 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_200.pt\n",
            "[2022-09-03 14:40:44,950 INFO] Training Loss 2.331423\n",
            "[2022-09-03 14:40:50,285 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.5.448.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:40:57,430 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.166.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:05,723 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.516.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:12,142 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.252.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:18,971 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_300.pt\n",
            "[2022-09-03 14:41:24,097 INFO] Training Loss 2.169494\n",
            "[2022-09-03 14:41:24,693 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.211.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:31,200 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.367.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:39,023 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.90.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:45,639 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.240.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:51,955 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.19.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:41:56,850 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_400.pt\n",
            "[2022-09-03 14:42:01,727 INFO] Training Loss 2.074965\n",
            "[2022-09-03 14:42:03,423 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.639.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:42:11,119 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.16.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:42:19,793 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.506.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:42:25,894 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.69.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:42:32,794 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.240.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:42:35,513 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_500.pt\n",
            "[2022-09-03 14:42:40,464 INFO] Training Loss 1.932538\n",
            "[2022-09-03 14:42:44,848 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.75.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:42:52,187 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.359.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:42:59,409 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.117.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:05,594 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.0.182.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:10,811 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.519.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:14,402 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_600.pt\n",
            "[2022-09-03 14:43:19,585 INFO] Training Loss 1.856814\n",
            "[2022-09-03 14:43:23,564 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.230.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:30,637 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.209.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:37,954 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.0.263.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:43,837 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.11.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:50,835 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.605.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:43:53,048 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_700.pt\n",
            "[2022-09-03 14:43:58,209 INFO] Training Loss 1.797119\n",
            "[2022-09-03 14:44:02,495 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.284.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:44:10,896 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.631.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:44:18,333 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.337.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:44:24,828 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.215.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:44:31,378 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.81.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:44:32,249 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_800.pt\n",
            "[2022-09-03 14:44:38,085 INFO] Training Loss 1.766943\n",
            "[2022-09-03 14:44:43,375 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.360.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:44:49,693 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.200.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:44:56,533 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.646.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:03,397 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.60.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:09,992 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.563.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:11,437 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_900.pt\n",
            "[2022-09-03 14:45:17,147 INFO] Training Loss 1.811203\n",
            "[2022-09-03 14:45:22,394 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.235.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:29,111 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.558.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:36,553 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.123.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:42,993 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.148.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:49,220 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.158.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:45:50,623 INFO] Step 1000/ 1000; xent: 1.89; lr: 0.0000632;  13 docs/s;    384 sec\n",
            "[2022-09-03 14:45:50,679 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_rnn/model_step_1000.pt\n",
            "[2022-09-03 14:45:55,856 INFO] Training Loss 0.000000\n",
            "[2022-09-03 14:45:56,152 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.67.bert.pt, number of examples: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-3. Transformer"
      ],
      "metadata": {
        "id": "rt6OrELKwi8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = './drive/MyDrive/colab/ExSum/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "!python ./SRC/train.py \\\n",
        "  -mode train \\\n",
        "  -encoder transformer \\\n",
        "  -dropout 0.1 \\\n",
        "  -bert_data_path ./drive/MyDrive/colab/ExSum/DATA/KLUE/bert_data/train/korean \\\n",
        "  -model_path ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer \\\n",
        "  -lr 2e-3 \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -report_every 1000\\\n",
        "  -save_checkpoint_steps 100 \\\n",
        "  -batch_size 1000 \\\n",
        "  -decay_method noam \\\n",
        "  -train_steps 1000 \\\n",
        "  -accum_count 2 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_transformer.txt \\\n",
        "  -use_interval true \\\n",
        "  -warmup_steps 200 \\\n",
        "  -ff_size 2048 \\\n",
        "  -inter_layers 2 \\\n",
        "  -heads 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqragDAcwi8h",
        "outputId": "a9170ff4-682b-4217-eb56-937c951c2970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-09-03 14:46:00,431 INFO] Device ID 0\n",
            "[2022-09-03 14:46:00,432 INFO] Device cuda\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-09-03 14:46:09,031 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): TransformerInterEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2022-09-03 14:46:09,077 INFO] * number of parameters: 121647617\n",
            "[2022-09-03 14:46:09,077 INFO] Start training...\n",
            "[2022-09-03 14:46:09,381 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.302.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:46:16,758 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.222.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:46:22,914 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.126.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:46:29,527 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.578.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:46:36,109 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.407.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:46:38,050 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_100.pt\n",
            "[2022-09-03 14:46:43,451 INFO] Training Loss 2.620507\n",
            "[2022-09-03 14:46:47,622 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.13.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:46:54,525 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.588.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:01,422 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.120.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:07,952 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.383.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:13,572 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.481.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:14,679 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_200.pt\n",
            "[2022-09-03 14:47:20,681 INFO] Training Loss 2.263351\n",
            "[2022-09-03 14:47:25,710 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.5.448.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:32,041 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.166.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:38,350 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.516.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:44,310 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.252.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:47:50,513 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_300.pt\n",
            "[2022-09-03 14:47:56,028 INFO] Training Loss 2.179846\n",
            "[2022-09-03 14:47:56,535 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.211.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:02,654 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.367.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:09,298 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.90.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:15,699 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.240.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:21,783 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.19.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:26,422 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_400.pt\n",
            "[2022-09-03 14:48:31,986 INFO] Training Loss 2.100392\n",
            "[2022-09-03 14:48:33,574 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.639.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:40,137 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.16.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:47,056 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.506.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:52,943 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.69.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:48:59,312 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.240.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:49:01,784 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_500.pt\n",
            "[2022-09-03 14:49:07,719 INFO] Training Loss 1.970808\n",
            "[2022-09-03 14:49:11,710 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.75.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:49:17,993 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.359.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:49:24,473 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.117.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:49:30,367 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.0.182.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:49:35,383 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.519.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:49:38,619 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_600.pt\n",
            "[2022-09-03 14:49:44,369 INFO] Training Loss 1.907218\n",
            "[2022-09-03 14:49:47,935 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.230.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:49:54,396 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.209.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:01,149 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.0.263.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:06,791 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.11.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:13,336 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.605.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:15,405 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_700.pt\n",
            "[2022-09-03 14:50:20,781 INFO] Training Loss 1.869573\n",
            "[2022-09-03 14:50:24,690 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.9.284.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:31,655 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.4.631.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:38,178 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.337.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:44,269 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.215.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:50,487 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.81.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:50:51,306 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_800.pt\n",
            "[2022-09-03 14:50:56,771 INFO] Training Loss 1.849246\n",
            "[2022-09-03 14:51:01,783 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.360.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:07,796 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.200.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:14,200 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.2.646.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:20,528 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.60.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:26,570 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.563.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:27,907 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_900.pt\n",
            "[2022-09-03 14:51:34,066 INFO] Training Loss 1.817947\n",
            "[2022-09-03 14:51:39,016 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.235.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:44,955 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.3.558.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:52,680 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.1.123.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:51:58,745 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.8.148.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:52:04,598 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.7.158.bert.pt, number of examples: 50\n",
            "[2022-09-03 14:52:05,925 INFO] Step 1000/ 1000; xent: 1.80; lr: 0.0000632;  14 docs/s;    357 sec\n",
            "[2022-09-03 14:52:05,930 INFO] Saving checkpoint ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt\n",
            "[2022-09-03 14:52:11,910 INFO] Training Loss 0.000000\n",
            "[2022-09-03 14:52:12,187 INFO] Loading train dataset from ./drive/MyDrive/Fast_Campus/ExSum/DATA/KLUE/bert_data/train/korean.train.6.67.bert.pt, number of examples: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 최종 평가 코드\n",
        "- train.py에서 mode를 test로 선택\n",
        "- valid 데이터 사용\n",
        "  - 이때 데이터 이름을 test로 변경해야 진행되므로 `korean.valid.{}.bert.pt` 데이터를 `korean.test.{}.bert.pt` 데이터로 이름 변경\n",
        "- **주의**\n",
        "  - test 시 pyrouge 라이브러리를 통해 rouge score를 계산하게 되는데, Colab 상에서는 dependency 문제로 인해 에러 발생\n",
        "  - 위의 Install libraries 가이드대로 pyrouge 설치 후 SRC, 데이터, 모델을 로컬 디스크에 다운로드 후 로컬에서 실행해야 함\n"
      ],
      "metadata": {
        "id": "8p2Doj9oVqWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-1. Classifier"
      ],
      "metadata": {
        "id": "seTm9qXDV502"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = './drive/MyDrive/colab/ExSum/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "resdirlocation = './drive/MyDrive/colab/ExSum/RESULT'\n",
        "os.makedirs(resdirlocation, exist_ok=True)\n",
        "\n",
        "tmpdirlocation = './drive/MyDrive/colab/ExSum/TEMP'\n",
        "os.makedirs(tmpdirlocation, exist_ok=True)\n",
        "\n",
        "\n",
        "!python ./SRC/train.py \\\n",
        "  -mode test \\\n",
        "  -bert_data_path ./drive/MyDrive/colab/ExSum/DATA/KLUE/bert_data/valid/korean \\\n",
        "  -model_path ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_classifier \\\n",
        "  -result_path ./drive/MyDrive/colab/ExSum/RESULT/ \\\n",
        "  -temp_dir ./drive/MyDrive/colab/ExSum/TEMP/ \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -batch_size 30000 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_classifier_test.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_classifier/model_step_1000.pt"
      ],
      "metadata": {
        "id": "CT1aNiH2trOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-2. RNN"
      ],
      "metadata": {
        "id": "aALd4FGgVzSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = './drive/MyDrive/colab/ExSum/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "resdirlocation = './drive/MyDrive/colab/ExSum/RESULT'\n",
        "os.makedirs(resdirlocation, exist_ok=True)\n",
        "\n",
        "tmpdirlocation = './drive/MyDrive/colab/ExSum/TEMP'\n",
        "os.makedirs(tmpdirlocation, exist_ok=True)\n",
        "\n",
        "!python ./SRC/train.py \\\n",
        "  -mode test \\\n",
        "  -bert_data_path ./drive/MyDrive/colab/ExSum/DATA/KLUE/bert_data/valid/korean \\\n",
        "  -model_path ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_rnn \\\n",
        "  -result_path ./drive/MyDrive/colab/ExSum/RESULT/ \\\n",
        "  -temp_dir ./drive/MyDrive/colab/ExSum/TEMP/ \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -batch_size 1000 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_rnn_test.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_rnn/model_step_1000.pt"
      ],
      "metadata": {
        "id": "EH6QJqFzwi8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-3. Transformer"
      ],
      "metadata": {
        "id": "Htxd3EV_V53O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdirlocation = './drive/MyDrive/colab/ExSum/LOG/KLUE'\n",
        "os.makedirs(logdirlocation, exist_ok=True)\n",
        "\n",
        "resdirlocation = './drive/MyDrive/colab/ExSum/RESULT'\n",
        "os.makedirs(resdirlocation, exist_ok=True)\n",
        "\n",
        "tmpdirlocation = './drive/MyDrive/colab/ExSum/TEMP'\n",
        "os.makedirs(tmpdirlocation, exist_ok=True)\n",
        "\n",
        "!python ./SRC/train.py \\\n",
        "  -mode test \\\n",
        "  -bert_data_path ./drive/MyDrive/colab/ExSum/DATA/KLUE/bert_data/valid/korean \\\n",
        "  -model_path ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer \\\n",
        "  -result_path ./drive/MyDrive/colab/ExSum/RESULT/ \\\n",
        "  -temp_dir ./drive/MyDrive/colab/ExSum/TEMP/ \\\n",
        "  -visible_gpus 0 \\\n",
        "  -gpu_ranks 0 \\\n",
        "  -world_size 1 \\\n",
        "  -batch_size 1000 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_transformer_test.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt"
      ],
      "metadata": {
        "id": "uA5zWK6Dwi8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "m2sIwVYYrkDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 세줄 요약 추론 코드 구현\n",
        "- train.py에서 mode를 inference로 선택\n",
        "- models > trainer.py의 `summ` 함수 참조\n"
      ],
      "metadata": {
        "id": "GoDb-5XfKPsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 추론 결과에 대한 정량적/정성적 평가 \n",
        "- 가장 성능이 좋았던 transformer encoder로 추론\n",
        "- valid.json 중 5개 검증"
      ],
      "metadata": {
        "id": "WLlbkGUAKTsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./SRC/train.py \\\n",
        "  -mode inference \\\n",
        "  -visible_gpus -1 \\\n",
        "  -gpu_ranks -1 \\\n",
        "  -world_size 0 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_transformer_inference.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt \\\n",
        "  -input_text ./drive/MyDrive/colab/ExSum/DATA/raw_data/valid_0.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd3sMIxT04Nl",
        "outputId": "a0359203-5453-4326-8a67-20b06551b267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 취소소송은 처분 등이 있음을 안 날부터 90일 이내에 제기하여야 하고,\n",
            "\n",
            "처분 등이 있은 날부터 1년을 경과하면\n",
            "\n",
            "제기하지 못하며( 행정소송법 제20조 제1항, 제2항), 청구취지를 변경하여 구 소가 취하되고 새로운 소가 제기된 것으로 변경되었을 때에 새로운 소에 대한 제소기간의 준수 등은 원칙적으로 소의 변경이 있은 때를 기준으로 하여야 한다.\n",
            "\n",
            "[2] 일반적으로 행정처분에 효력기간이 정하여져 있는 경우에는 그 기간의 경과로 그 행정처분의 효력은 상실되며,\n",
            "\n",
            "다만 허가에 붙은 기한이 그 허가된 사업의 성질상 부당하게 짧은 경우에는 이를 그 허가 자체의 존속기간이 아니라 그 허가조건의 존속기간으로 보아 그 기한이 도래함으로써 그 조건의 개정을 고려한다는 뜻으로 해석할 수 있다.\n",
            "\n",
            "[3] 사도개설허가에서 정해진 공사기간 내에 사도로 준공검사를 받지 못한 경우,\n",
            "\n",
            "이 공사기간을 사도개설허가 자체의 존속기간(유효기간)으로 볼 수 없다는 이유로 사도개설허가가 당연히 실효되는 것은 아니라고 한 사례.\n",
            "[2022-09-07 08:52:50,399 INFO] Loading checkpoint from ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt\n",
            "gpu_rank 0\n",
            "[2022-09-07 08:53:15,105 INFO] * number of parameters: 121647617\n",
            "['제기하지 못하며( 행정소송법 제20조 제1항, 제2항), 청구취지를 변경하여 구 소가 취하되고 새로운 소가 제기된 것으로 변경되었을 때에 새로운 소에 대한 제소기간의 준수 등은 원칙적으로 소의 변경이 있은 때를 기준으로 하여야 한다.', '[1] 취소소송은 처분 등이 있음을 안 날부터 90일 이내에 제기하여야 하고,', '[2] 일반적으로 행정처분에 효력기간이 정하여져 있는 경우에는 그 기간의 경과로 그 행정처분의 효력은 상실되며,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./SRC/train.py \\\n",
        "  -mode inference \\\n",
        "  -visible_gpus -1 \\\n",
        "  -gpu_ranks -1 \\\n",
        "  -world_size 0 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_transformer_inference.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt \\\n",
        "  -input_text ./drive/MyDrive/colab/ExSum/DATA/raw_data/valid_6000.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRDU5U2zIqlb",
        "outputId": "e232cb9d-0322-4f89-a6b2-22d143c60e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "애플이 자사 제품을 잇따라 리콜하고 있다.\n",
            "\n",
            "과거 고장이 없는 품질로 유명했지만 비교적 최근 출시한 제품에 문제가 연이어 발생하고 있다.\n",
            "\n",
            "품질관리에 구멍이 뚫린 것 아니냐는 우려의 목소리가 나온다.\n",
            "\n",
            "IT 매체 나인투파이브맥에 따르면 애플이 지난해 출시한 일부 맥북 에어 부품에 문제가 있는 것을 확인하고 무상 교체를 실시할 계획이라고 전했다.\n",
            "\n",
            "리콜 부품은 로직 보드다.\n",
            "\n",
            "로직 보드의 정확한 문제점은 공개되지 않았지만 전원이 켜지지 않는 이상이 발생한 것으로 알려졌다.\n",
            "\n",
            "해당 문제는 2018년 출시된 맥북 에어 제품 중 일부에 해당되는 것으로 알려졌다.\n",
            "\n",
            "제품을 가진 고객은 일련번호를 통해 문제가 있는 기기 여부를 확인 후 무상 수리를 받을 수 있다.\n",
            "\n",
            "통상적으로 리콜 프로그램을 시행하는 경우 무상 수리기간은 제품 구매일로부터 4년이다.\n",
            "\n",
            "애플이 잇따라 제품 리콜 사태에 직면하자 시장에서는 품질관리 문제를 제기하고 있다.\n",
            "\n",
            "하드웨어와 소프트웨어를 모두 자체 개발하는 애플이 만든 제품에는 과거 고장이 거의 없다는 소비자 신뢰가 컸지만 최근에는 달라지고 있다는 의견이다.\n",
            "\n",
            "애플은 지난 6월 맥북 프로 레티나 15인치 모델의 배터리 리콜을 발표했다.\n",
            "\n",
            "2015년 9월부터 2017년 2월 사이에 판매된 '2015 Mid' 모델이 해당된다.\n",
            "\n",
            "이에 앞선 5월에는 2016년 10월부터 2018년 2월 사이 판매된 맥북 프로 13인치 모델의 백라이트 불량으로 디스플레이 부품 리콜이 있었다.\n",
            "\n",
            "소비자들이 말하는 애플의 품질관리 불량 문제는 더 폭넓게 제기되고 있다.\n",
            "\n",
            "리콜 프로그램이 발표되지 않았지만 제품 자체적인 문제점이 곳곳에서 발견되고 있다는 주장이다.\n",
            "\n",
            "애플 아이패드의 경우에는 제품이 휘어지는 '벤딩 게이트' 문제가 계속 제보되고 있다.\n",
            "\n",
            "최신 아이패드 프로도 12.9인치, 11인치 두 모델 모두 제품 외장 케이스를 사용해도 기기가 휘어지는 경우가 많은 것으로 알려졌다.\n",
            "\n",
            "애플에서 수리 문의를 한 이들에 따르면 회사는 사용 환경에 따라 발생하는 문제라는 입장으로 현재 공식적으로 문제를 확인하지 않았다.\n",
            "[2022-09-07 08:53:25,933 INFO] Loading checkpoint from ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt\n",
            "gpu_rank 0\n",
            "[2022-09-07 08:53:35,587 INFO] * number of parameters: 121647617\n",
            "['IT 매체 나인투파이브맥에 따르면 애플이 지난해 출시한 일부 맥북 에어 부품에 문제가 있는 것을 확인하고 무상 교체를 실시할 계획이라고 전했다.', '해당 문제는 2018년 출시된 맥북 에어 제품 중 일부에 해당되는 것으로 알려졌다.', \"2015년 9월부터 2017년 2월 사이에 판매된 '2015 Mid' 모델이 해당된다.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./SRC/train.py \\\n",
        "  -mode inference \\\n",
        "  -visible_gpus -1 \\\n",
        "  -gpu_ranks -1 \\\n",
        "  -world_size 0 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_transformer_inference.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt \\\n",
        "  -input_text ./drive/MyDrive/colab/ExSum/DATA/raw_data/valid_12000.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW7I-S_FJyvI",
        "outputId": "a5e7eafc-bbea-4341-b793-0b17edac0150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "앞으로 증권형 크라우드펀딩 전문투자자에 창업기획자(액셀러레이터)가 추가된다.\n",
            "\n",
            "금융위원회는 27일 정부서울청사에서 '기존규제정비위원회'를 열고 이 같은 내용을 포함한 자산운용 분야 규제 96건을 심의, 이 가운데 24건을 개선하기로 결정했다고 밝혔다.\n",
            "\n",
            "유형별로는 영업행위 관련 규제 12건, 시장질서 유지 및 건전성 규제 8건, 투자자 보호 규제 4건 등이다.\n",
            "\n",
            "증권형 크라우드 펀딩에 투자금액 제한이 없는 전문투자자로 액셀러레이터를 포함하기로 했다.\n",
            "\n",
            "액셀러레이터는 중소기업창업지원법에 따라 창업 3년 이내 초기 창업자를 상대로 마케팅 지원 등 투자·육성 업무를 수행하는 기관이나 단체다.\n",
            "\n",
            "현재 증권형 크라우드펀딩 발행기업을 창업 7년 이내 중소기업에서 모든 중소기업으로 확대하는 내용의 자본시장법 개정안이 추진 중이다.\n",
            "\n",
            "법 개정 이 되면 관련 조문을 정비할 예정이다.\n",
            "\n",
            "상품 다양화와 외화보유 수요 등을 감안해 외화로 투자·운용하는 머니마켓펀드(MMF) 등 '외화표시 단기금융집합투자기구' 도입이 추진된다.\n",
            "\n",
            "현행법상 MMF의 투자대상은 '원화' 표시 자산으로 한정하고 있다.\n",
            "\n",
            "금융위는 시행령에 '외화' 표시 MMF 도입 근거를 마련하고, 감독규정에 외화표시 MMF 운용시 준수사항 등을 규정하기로 했다.\n",
            "\n",
            "또 사모투자 공모 재간접펀드의 최소투자금액 규제을 폐지한다.\n",
            "\n",
            "외국펀드의 국내판매 현황 보고의무도 완화된다.\n",
            "\n",
            "현행법상 외국펀드의 판매를 대행하는 증권사는 외국펀드의 국내 판매현황을 매월 금감원장과 금투협회에 보고해야 한다.\n",
            "\n",
            "이제는 보고대상을 금투협회로 일원화한다.\n",
            "\n",
            "일반투자자의 투자 기회 확대 등을 위해 사모투자 공모 재간접펀드의 최소투자금액(500만원) 규제가 폐지된다.\n",
            "\n",
            "투자일임·신탁업자의 투자성향 확인 주기도 매분기에서 연 1회로 줄어든다.\n",
            "\n",
            "단 투자자에게 투자성향 등 변경시에 회신해달라는 내용을 매분기 통지해야 한다.\n",
            "\n",
            "이밖에 특정금전신탁 계약체결과 운용방법의 변경을 '대면' 뿐 아니라 '비대면' 방식으로도 허용할 예정이다.\n",
            "\n",
            "금융위는 해당 17건의 과제에 대해서는 올해 말까지 감독규정 개선을 완료하고 외화 표시 MMF 도입 등 신규 개선 과제 7건은 연내 감독규정 개정안을 입법예고한다.\n",
            "\n",
            "법령 개정이 필요한 사항은 법령 정비 이후 감독규정 개정을 추진한다.\n",
            "[2022-09-07 08:53:44,778 INFO] Loading checkpoint from ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt\n",
            "gpu_rank 0\n",
            "[2022-09-07 08:53:50,274 INFO] * number of parameters: 121647617\n",
            "[\"금융위원회는 27일 정부서울청사에서 '기존규제정비위원회'를 열고 이 같은 내용을 포함한 자산운용 분야 규제 96건을 심의, 이 가운데 24건을 개선하기로 결정했다고 밝혔다.\", '유형별로는 영업행위 관련 규제 12건, 시장질서 유지 및 건전성 규제 8건, 투자자 보호 규제 4건 등이다.', '액셀러레이터는 중소기업창업지원법에 따라 창업 3년 이내 초기 창업자를 상대로 마케팅 지원 등 투자·육성 업무를 수행하는 기관이나 단체다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./SRC/train.py \\\n",
        "  -mode inference \\\n",
        "  -visible_gpus -1 \\\n",
        "  -gpu_ranks -1 \\\n",
        "  -world_size 0 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_transformer_inference.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt \\\n",
        "  -input_text ./drive/MyDrive/colab/ExSum/DATA/raw_data/valid_18000.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH3-xYy5J0I9",
        "outputId": "6cd5cd30-0023-4837-b985-e2e1ada22625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'을지태극연습' 첫시행 키리졸브(KR)-독수리훈련(FE)-을지프리덤가디언(UFG) 등 3대 한미연합훈련이 모두 역사 속으로 사라질 전망이다.\n",
            "\n",
            "지난 3일 한미 국방당국은 전날 양국 국방장관 전화통화를 갖고 키리졸브와 독수리훈련 폐지방침을 확정했다고 밝힌 바 있다.\n",
            "\n",
            "여기에 매년 8월경 열리던 UFG연습도 폐지방침을 정하고 대체방안을 마련한 것으로 알려졌다.\n",
            "\n",
            "정부 당국에 따르면 UFG연습 가운데 정부연습인 '을지연습'과 한국군 단독연습인 '태극연습'을 통합해 새로운 형태의 '을지태극연습'을 5월말 나흘 일정으로 진행할 예정이다.\n",
            "\n",
            "8월에 예정돼 있던 UFG연습은 폐지할 방침인 가운데 전시작전통제권(전작권) 전환을 위한 1단계 연합검증(IOC)을 시행할 예정이다.\n",
            "\n",
            "UFG라는 명칭을 사용하지 않는 대신 '19-2동맹'이나 또 다른 약칭으로 불릴 전망이다.\n",
            "\n",
            "이에 따라 UFG 연습은 43년 만에 폐지될 전망이다.\n",
            "\n",
            "을지연습은 1968년 북한 무장공비 청와대 기습사건인 '1.21 사태를 계기로 시작된 정부 차원의 군사지원훈련으로 국가위기관리, 국가 총력전 대응 역량을 총체적으로 점검하는 훈련이다.\n",
            "\n",
            "시·군·구 이상 행정기관과 공공기관·단체 등 4000여개 기관에서 48만여명이 참여하는 정부 최대 전시 훈련으로 꼽힌다.\n",
            "\n",
            "태극연습은 합참 주도하에 전구(戰區) 작전 수행 능력을 배양하고, 합동전력 및 부대구조 발전 소요를 도출하고자 연례적으로 실시한 전구급 지휘소연습(CPX)이다.\n",
            "\n",
            "1994년 평시 작전통제권을 환수하면서 이듬해 실무급 연습을 시작했고, 1996년 '압록강연습'으로 명명했다가 2004년 '태극연습'으로 명칭을 변경했다.\n",
            "\n",
            "UFG연습은 1954년부터 유엔사 주관으로 시행하던 포커스렌즈 연습과 을지연습을 1976년 통합하면서 시작됐다.\n",
            "\n",
            "훈련 명칭은 2008년부터 을지포커스렌즈(UFL) 연습에서 UFG 연습으로 변경했다.\n",
            "\n",
            "정부 연습과 통합한 지 43년 만에, 명칭을 변경해 시행하지 11년 만에 폐지된다.\n",
            "\n",
            "지난해에는 달라진 한반도 정세 분위기와 남북화해 분위기 속에서 UFG 연습을 하지 않았다.\n",
            "\n",
            "이번에 새로 실시하는 '을지태극연습'은 매년 8월 UFG 연습과 함께 실시한 을지연습과 통상 5월에 실시하는 한국군 단독 지휘소연습(CPX)을 통합한 것으로 외부로부터 무력공격을 격퇴하는 군의 독자적인 작전 수행 능력 배양 뿐 아니라 테러, 대규모 재난 대응 등을 포함하는 포괄적 안보개념을 적용해 실시된다.\n",
            "\n",
            "앞서 지난 2일 저녁 정경두 국방부 장관과 패트릭 섀너핸 미국 국방부 장관 대행은 전화통화를 갖고 키리졸브 연습과 독수리훈련을 폐지키로 최종 결정한 바 있다.\n",
            "\n",
            "비록 베트남 하노이 2차 북미 정상회담이 불발로 끝이 났지만 한미 국방당국의 이 같은 결정은 비핵화를 위한 외교적 노력을 확실하게 뒷받침하겠다는 의지를 표명한 것으로 해석됐다.\n",
            "\n",
            "여기에 UFG까지 폐지키로 함에 따라 한미는 대규모 3대 연합훈련을 모두 중단했고, 북한은 핵·탄도 미사일 시험을 더는 하지 않는 이른바 '쌍중단'이 유지되는 모양새가 됐다.\n",
            "[2022-09-07 08:53:58,406 INFO] Loading checkpoint from ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt\n",
            "gpu_rank 0\n",
            "[2022-09-07 08:54:03,865 INFO] * number of parameters: 121647617\n",
            "[\"'을지태극연습' 첫시행 키리졸브(KR)-독수리훈련(FE)-을지프리덤가디언(UFG) 등 3대 한미연합훈련이 모두 역사 속으로 사라질 전망이다.\", '지난 3일 한미 국방당국은 전날 양국 국방장관 전화통화를 갖고 키리졸브와 독수리훈련 폐지방침을 확정했다고 밝힌 바 있다.', '여기에 매년 8월경 열리던 UFG연습도 폐지방침을 정하고 대체방안을 마련한 것으로 알려졌다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./SRC/train.py \\\n",
        "  -mode inference \\\n",
        "  -visible_gpus -1 \\\n",
        "  -gpu_ranks -1 \\\n",
        "  -world_size 0 \\\n",
        "  -log_file ./drive/MyDrive/colab/ExSum/LOG/KLUE/bert_transformer_inference.txt \\\n",
        "  -test_from ./drive/MyDrive/colab/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt \\\n",
        "  -input_text ./drive/MyDrive/colab/ExSum/DATA/raw_data/valid_24000.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXYMvIh_J1jw",
        "outputId": "0c754300-722e-4471-8073-bb23920b927b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "무신사, 번개장터 같은 후발 이커머스업체들이 'Z세대'를 집중 공략하며 생존력을 키우고 있는 것으로 나타났다.\n",
            "\n",
            "Z세대는 1995년 이후 태어난 신흥 소비층이자 '디지털 원주민(네이티브)'으로 불린다.\n",
            "\n",
            "전체 인구의 12.5%(645만명)를 차지한다.\n",
            "\n",
            "14일 이커머스업계에 따르면 무신사 번개장터 지그재그 아이디어스 등 후발 이커머스업체들이 이베이코리아 쿠팡 11번가 위메프 등 선발 이커머스업체들이 장악한 국내 이커머스시장에서 서서히 존재감을 드러내고 있다.\n",
            "\n",
            "뒤늦게 이커머스시장에 뛰어든 만큼 틈새공략으로 시장을 개척하고 있다는 평가다.\n",
            "\n",
            "특히 기존 이커머스업체들이 미처 공략하지 못한 Z세대를 손님으로 끌어 들이는 데 주력하고 있다.\n",
            "\n",
            "Z세대는 현재 336만명이 성인이 돼 취업 시장에 진입한 상태다.\n",
            "\n",
            "이커머스업체 한 관계자는 '후발 이커머스업체들은 컴퓨터보다 스마트폰에 익숙하고 텍스트보다 이미지, 동영상을 선호하면서도 구매에 있어서는 다른 세대에 비해 안정성과 실용성을 추구하는 Z세대 취향을 공략하고 있다'고 말했다.\n",
            "\n",
            "실제 모바일 애플리케이션 분석 플랫폼 앱애니가 세대별 실사용자 기준 상위 25위 앱 중 Z세대 비중이 가장 많은 앱 상위 10위곳 가운데 후발 이커머스 4곳이 포함됐다.\n",
            "\n",
            "무신사는 2003년 온라인 패션 커뮤니티 '무지하게 신발 사진이 많은 곳'으로 출발해 최근 국내 10번째 유니콘기업(기업가치 1조원 이상 비상장사) 반열에 오른 국내 1위 온라인 패션 플랫폼이다.\n",
            "\n",
            "무신사는 18~24세 소비자가 전체 회원 가운데 45%를 차지할 만큼 Z세대 선호도가 높다.\n",
            "\n",
            "스트리트 패션(길거리 패션)에 대한 관심이 높은 Z세대가 이 부분에 강점을 가진 무신사로 몰리고 있다는 분석이다.\n",
            "\n",
            "지난해 거래액 4500억원, 올해는 1조1000억원으로 전망된다.\n",
            "\n",
            "모바일 중고마켓 번개장터는 사용자 가운데 60% 가량이 1020세대이며 이중 절반 이상이 Z세대다.\n",
            "\n",
            "25세 이하 월간 순방문자수는 올해 2월 300만명을 넘었다.\n",
            "\n",
            "물품 등록, 흥정, 직거래·택배거래, 결제 등 중고거래 전과정이 모바일 앱 하나로 가능하다.\n",
            "\n",
            "최근엔 빠르고 편리하게 원하는 물품을 찾고 거래할 수 있도록 검색·추천 시스템을 강화하고 있다.\n",
            "\n",
            "Z세대 맞춤형 서비스인 셈이다.\n",
            "\n",
            "올해 사상 첫 연간 거래액 1조원 돌파가 유력하다.\n",
            "\n",
            "지그재그는 여성 쇼핑몰 모음 플랫폼이다.\n",
            "\n",
            "동대문 의류를 기반으로 하는 여성 쇼핑몰을 한데 모아 이용할 수 있게 해주는 앱 서비스로 약 3500개의 쇼핑몰 정보를 제공한다.\n",
            "\n",
            "구매도 가능하다.\n",
            "\n",
            "원하는 옷을 찾아 개별 온라인 사이트를 헤맬 필요 없이 유행에 따라 가장 인기 있는 쇼핑몰 등을 한눈에 쉽게 알 수 있다.\n",
            "\n",
            "수천개 온라인 쇼핑몰이 들어와 있기 때문에 1만~3만원으로 최신 유행 옷을 고를 수 있다.\n",
            "\n",
            "역시 Z세대들 호응이 좋다.\n",
            "\n",
            "지그재그 사용자의 77%는 1020세대다.\n",
            "\n",
            "설립 4년 만인 지난 6월 누적 거래액 1조3000억원을 돌파했다.\n",
            "\n",
            "온라인 핸드메이드 마켓 아이디어스는 Z세대와 밀레니얼 세대(1980년대 초반 ~ 2000년대 초반 출생한 세대) 회원들에 힘입어 월간 이용자수가 260만명을 넘었다.\n",
            "\n",
            "입점 작가 수는 1만1000명이다.\n",
            "\n",
            "수공예품과 수제 먹거리, 농축수산물 등 16만개의 상품을 선보이고 있다.\n",
            "[2022-09-07 08:54:13,776 INFO] Loading checkpoint from ./drive/MyDrive/Fast_Campus/ExSum/MODEL/KLUE/bert_transformer/model_step_1000.pt\n",
            "gpu_rank 0\n",
            "[2022-09-07 08:54:19,178 INFO] * number of parameters: 121647617\n",
            "[\"무신사, 번개장터 같은 후발 이커머스업체들이 'Z세대'를 집중 공략하며 생존력을 키우고 있는 것으로 나타났다.\", \"Z세대는 1995년 이후 태어난 신흥 소비층이자 '디지털 원주민(네이티브)'으로 불린다.\", '14일 이커머스업계에 따르면 무신사 번개장터 지그재그 아이디어스 등 후발 이커머스업체들이 이베이코리아 쿠팡 11번가 위메프 등 선발 이커머스업체들이 장악한 국내 이커머스시장에서 서서히 존재감을 드러내고 있다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVXvDkO7J7Tz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}